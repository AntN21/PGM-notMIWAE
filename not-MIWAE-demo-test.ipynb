{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":1737,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.distributions import Distribution\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.impute import SimpleImputer"]},{"cell_type":"code","execution_count":1738,"metadata":{},"outputs":[],"source":["from matplotlib.animation import FuncAnimation\n","from IPython.display import HTML\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":1739,"metadata":{},"outputs":[],"source":["from typing import Any ,List"]},{"cell_type":"markdown","metadata":{},"source":["General case:\n","- Choose a prior for $Z$: $p(Z)$.\n","- Choose an observation model: $p_\\theta(X|Z)$\n","- Choose a variational posterior: $q_{\\gamma}(\\mathbf{z} | \\mathbf{x})$\n","\n","- Choose a missing model: $p_{\\phi}(\\mathbf{S} | \\mathbf{X^o, X^m})$\n","\n","\n","The ELBO in the MNAR case is\n","\n","$$ E_{(\\mathbf{z}_1, \\mathbf{x}_1^m)...(\\mathbf{z}_K, \\mathbf{x}_K^m)} \\left[ \\log \\frac{1}{K} \\sum_{k=1}^K \\frac{p_{\\phi}(\\mathbf{s} | \\mathbf{x}^o, \\mathbf{x}_k^m) p_{\\theta}(\\mathbf{x}^o | \\mathbf{z}_k) p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z} | \\mathbf{x}^o)} \\right]$$"]},{"cell_type":"markdown","metadata":{},"source":["### Classic case\n","The model we are building has a Gaussian prior and a Gaussian observation model (also the decoder ($z \\rightarrow x$) ),\n","\n","$$ p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{z} | \\mathbf{0}, \\mathbf{I})$$\n","\n","$$ p_\\theta(\\mathbf{x} | \\mathbf{z}) = \\mathcal{N}(\\mathbf{x} | \\mathbf{\\mu}_{\\theta}(\\mathbf{z}), \\sigma^2\\mathbf{I})$$\n","\n","$$ p_\\theta(\\mathbf{x}) = \\int p_\\theta(\\mathbf{x} | \\mathbf{z})p(\\mathbf{z}) d\\mathbf{z}$$\n","\n","where $\\mathbf{\\mu}_{\\theta}(\\mathbf{z}): \\mathbb{R}^d \\rightarrow \\mathbb{R}^p $ in general is a deep neural net, but in this case is a linear mapping, $\\mathbf{\\mu} = \\mathbf{Wz + b}$.\n","\n","The variational posterior (also the encoder ($x \\rightarrow z$) ) is also Gaussian\n","\n","$$q_{\\gamma}(\\mathbf{z} | \\mathbf{x}) = \\mathcal{N}(\\mathbf{z} | \\mu_{\\gamma}(\\mathbf{x}), \\sigma_{\\gamma}(\\mathbf{x})^2 \\mathbf{I})$$\n","\n","If the missing process is *missing at random*, it is ignorable and the ELBO becomes, as described in [the MIWAE paper](https://arxiv.org/abs/1812.02633)\n","\n","$$ E_{\\mathbf{z}_1...\\mathbf{z}_K} \\left[ \\log \\frac{1}{K}\\sum_{k=1}^K \\frac{p_{\\theta}(\\mathbf{x^o} | \\mathbf{z}_k)p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z}_k | \\mathbf{x^o})} \\right] $$\n","\n","When the missing process is MNAR it is non-ignorable and we need to include the missing model. In this example we include the missing model as a logistic regression in each feature dimension\n","\n","$$ p_{\\phi}(\\mathbf{s} | \\mathbf{x^o, x^m}) = \\text{Bern}(\\mathbf{s} | \\pi_{\\phi}(\\mathbf{x^o, x^m}))$$\n","\n","$$ \\pi_{\\phi, j}(x_j) = \\frac{1}{1 + e^{-\\text{logits}_j}} $$\n","\n","$$ \\text{logits}_j = W_j (x_j - b_j) $$\n","\n","The ELBO in the MNAR case becomes\n","\n","$$ E_{(\\mathbf{z}_1, \\mathbf{x}_1^m)...(\\mathbf{z}_K, \\mathbf{x}_K^m)} \\left[ \\log \\frac{1}{K} \\sum_{k=1}^K \\frac{p_{\\phi}(\\mathbf{s} | \\mathbf{x}^o, \\mathbf{x}_k^m) p_{\\theta}(\\mathbf{x}^o | \\mathbf{z}_k) p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z} | \\mathbf{x}^o)} \\right]$$\n","\n","with $ z \\sim q_{\\gamma}(z|x^o), x^m\\sim p_\\theta(x^m|z)$"]},{"cell_type":"markdown","metadata":{},"source":["### Constant to define\n","\n"," - $K$ = $n_{\\text{samples}}$ the number of sample to estimate the expectation\n"," - $n_{\\text{latent}}$ the dimension of the latent space where $z$ lives\n"]},{"cell_type":"markdown","metadata":{},"source":["## Imputation\n","\n"," - RMSE imputation (easy to implement)\n","$$\n","\\hat{x}^m = \\mathbb{E}[x^m|x^o,s] \\approx \\sum_{k=1}^K \\alpha_k \\mathbb{E}[x^m|x^o,s]  ~~\\text{with} ~~ \\alpha _ k =\\frac{w_k}{w_1 + ... + w_K}\n","$$\n"," - Absolute value imputation (harder) 5NOT IMPLEMENTED\n","$$\n","F_j(x_j)= \\mathbb{E}[\\mathbb{1}_{x_j^m \\leq x_j}|x^o,s] \\approx \\sum_{k=1}^K \\alpha_k F_{x_j|x^o,s}(x_j) ~~\\text{with} ~~ \\alpha_k =\\frac{w_k}{w_1 + ... + w_K}\n","$$"]},{"cell_type":"markdown","metadata":{},"source":["### Load data\n","Here we use the white-wine dataset from the UCI database"]},{"cell_type":"code","execution_count":1740,"metadata":{},"outputs":[],"source":["url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n","data = np.array(pd.read_csv(url, low_memory=False, sep=';'))\n","# ---- drop the classification attribute\n","data = data[:, :-1]"]},{"cell_type":"markdown","metadata":{},"source":["### Settings"]},{"cell_type":"code","execution_count":1741,"metadata":{},"outputs":[],"source":["N, D = data.shape\n","n_latent = D - 1\n","n_hidden = 128\n","n_samples = 20\n","max_iter = 30000\n","batch_size = 16"]},{"cell_type":"markdown","metadata":{},"source":["### Standardize data"]},{"cell_type":"code","execution_count":1742,"metadata":{},"outputs":[],"source":["# ---- standardize data\n","data = data - np.mean(data, axis=0)\n","data = data / np.std(data, axis=0)\n","\n","# ---- random permutation\n","p = np.random.permutation(N)\n","data = data[p, :]\n","\n","# ---- we use the full dataset for training here, but you can make a train-val split\n","Xtrain = data.copy()\n","Xval = Xtrain.copy()"]},{"cell_type":"markdown","metadata":{},"source":["### Introduce missing \n","Here we denote\n","- Xnan: data matrix with np.nan as the missing entries\n","- Xz: data matrix with 0 as the missing entries\n","- S: missing mask \n","\n","The missing process depends on the missing data itself:\n","- in half the features, set the feature value to missing when it is higher than the feature mean"]},{"cell_type":"code","execution_count":1743,"metadata":{},"outputs":[],"source":["def transform(data: np.array, d1, d2, threshold, prob, sign: int = 1) -> np.array:\n","    \"\"\"\n","    Introduce missing data.\n","    Mechanism: sign * x[i, d2] > threshold => x[i, d1] missing with probability prob.\n","    \n","    Args:\n","    - data (np.array): Input data array.\n","    - d1 (int): Index of the column where missing data will be introduced.\n","    - d2 (int): Index of the column used for the threshold comparison.\n","    - threshold (float): Threshold value for the comparison.\n","    - prob (float): Probability of introducing missing data.\n","    - sign (int, optional): Sign of the comparison (1 or -1). Default is 1.\n","\n","    Returns:\n","    - np.array: Transformed data with missing values introduced based on the specified mechanism.\n","    \"\"\"\n","    transformed_data = np.copy(data)\n","\n","    # Apply the transformation based on the specified mechanism\n","    mask = sign * data[:, d2] > threshold\n","    missing_values = np.random.choice([True, False], size=len(mask), p=[prob, 1 - prob])\n","    transformed_data[mask & missing_values, d1] = np.nan\n","\n","    return transformed_data"]},{"cell_type":"code","execution_count":1744,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["595 / 53878\n"]}],"source":["test = transform(data,1,1,0.5,0.5)\n","print(f'{np.isnan(test).sum()} / {test.shape[0]*test.shape[1]}')"]},{"cell_type":"code","execution_count":1745,"metadata":{},"outputs":[],"source":["# ---- introduce missing process\n","Xnan = Xtrain.copy()\n","Xz = Xtrain.copy()\n","\n","mean = np.mean(Xnan[:, :int(D / 2)], axis=0)\n","ix_larger_than_mean = Xnan[:, :int(D / 2)] > mean\n","\n","Xnan[:, :int(D / 2)][ix_larger_than_mean] = np.nan\n","Xz[:, :int(D / 2)][ix_larger_than_mean] = 0\n","\n","S = np.array(~np.isnan(Xnan), dtype=np.float32)"]},{"cell_type":"code","execution_count":1746,"metadata":{},"outputs":[],"source":["def check_nan(tens,name=None):\n","    if torch.isnan(tens).any().item():\n","        print(name)\n","        print(tens)"]},{"cell_type":"markdown","metadata":{},"source":["## Define Distributions"]},{"cell_type":"code","execution_count":1747,"metadata":{},"outputs":[],"source":["class Distributions():\n","    def __init__(self) -> None:\n","        pass\n","    def rsample(self, sample_shape):\n","        print(\"Not implemented\")\n","        pass\n","    def log_prob(self, value):\n","        print(\"Not implemented\")\n","        pass"]},{"cell_type":"code","execution_count":1748,"metadata":{},"outputs":[],"source":["class GaussDistribution(Distributions):\n","    \"\"\"\n","    Gaussian distribution with mean (mu) and standard deviation (sigma).\n","\n","    Parameters:\n","    - loc (Any): Mean of the distribution. Default is 0.\n","    - scale (Any): Standard deviation of the distribution. Default is 1.\n","\n","    Methods:\n","    - rsample(sample_shape): Generates random samples from the distribution.\n","    - log_prob(value): Computes the log probability of a given value under the distribution.\n","    \"\"\"\n","\n","    def __init__(self, loc: Any = 0., scale: Any = 1.) -> None:\n","        \"\"\"\n","        Initializes the Gaussian distribution with given mean and standard deviation.\n","\n","        Args:\n","        - loc (Any): Mean of the distribution. Default is 0.\n","        - scale (Any): Standard deviation of the distribution. Default is 1.\n","        \"\"\"\n","        super().__init__()\n","        \n","        if not torch.is_tensor(loc):\n","            self.mu = torch.tensor(loc, dtype=torch.float32)\n","        else:\n","            self.mu = loc\n","\n","        if not torch.is_tensor(scale):\n","            self.sigma = torch.tensor(scale, dtype=torch.float32)\n","        else:\n","            self.sigma = scale\n","\n","    def sample(self, sample_shape:torch.Size = torch.Size()):\n","        \"\"\"\n","        Generates random samples from the Gaussian distribution.\n","\n","        Args:\n","        - sample_shape: Shape of the random samples to be generated.\n","\n","        Returns:\n","        - samples: Random samples from the distribution.\n","        \"\"\"\n","        if not isinstance(sample_shape, torch.Size):\n","            sample_shape = torch.Size(sample_shape)\n","        \n","        shape = sample_shape + self.mu.size()\n","        with torch.no_grad():\n","            eps = torch.randn(shape, dtype=self.mu.dtype)\n","            return self.mu + eps * self.sigma\n","    \n","    def rsample(self, sample_shape:torch.Size = torch.Size()):\n","        \"\"\"\n","        Generates random samples from the Gaussian distribution.\n","\n","        Args:\n","        - sample_shape: Shape of the random samples to be generated.\n","\n","        Returns:\n","        - samples: Random samples from the distribution.\n","        \"\"\"\n","        if not isinstance(sample_shape, torch.Size):\n","            sample_shape = torch.Size(sample_shape)\n","        \n","        shape = sample_shape + self.mu.size()\n","\n","        eps = torch.randn(shape, dtype=self.mu.dtype)\n","        \n","        return self.mu + eps * self.sigma\n","    \n","\n","    def log_prob(self, value):\n","        \"\"\"\n","        Computes the log probability of a given value under the Gaussian distribution.\n","\n","        Args:\n","        - value: Tensor of values for which log probabilities are computed.\n","\n","        Returns:\n","        - log_p: Log probabilities of the given values.\n","        \"\"\"\n","        eps = torch.finfo(torch.float32).eps\n","\n","        log_p = - 0.5 * torch.log(2 * torch.tensor(np.pi, dtype=torch.float32)) \\\n","                - 0.5 * torch.log(self.sigma**2 + eps) \\\n","                - 0.5 * torch.square(value - self.mu) / (self.sigma**2 + eps)\n","\n","        return log_p\n"]},{"cell_type":"code","execution_count":1749,"metadata":{},"outputs":[],"source":["class BernoulliDistribution(Distributions):\n","    \"\"\"\n","    Bernoulli distribution with parameter (p).\n","\n","    Parameters:\n","    - p (Any): Probability of success. Default is 0.5.\n","\n","    Methods:\n","    - sample(sample_shape): Generates random samples from the distribution.\n","    - rsample(sample_shape): Generates random samples with reparameterization.\n","    - log_prob(value): Computes the log probability of a given value under the distribution.\n","    \"\"\"\n","\n","    def __init__(self, probs: Any = None, logits = None) -> None:\n","        \"\"\"\n","        Initializes the Bernoulli distribution with the given probability.\n","\n","        Args:\n","        - probs (Any): Probability of success. Default is 0.5.\n","        \"\"\"\n","        super().__init__()\n","        if probs is not None:\n","            if not torch.is_tensor(probs):\n","                p = torch.tensor(probs, dtype=torch.float32)\n","            else:\n","                p = probs\n","        \n","        elif logits is not None:\n","            if not torch.is_tensor(logits):\n","                logip = torch.tensor(logits, dtype=torch.float32)\n","            else:\n","                logip = logits\n","            p = torch.sigmoid(logip)\n","            \n","        self.p = p\n","\n","    def sample(self, sample_shape: torch.Size = torch.Size()):\n","        \"\"\"\n","        Generates random samples from the Bernoulli distribution.\n","\n","        Args:\n","        - sample_shape: Shape of the random samples to be generated.\n","\n","        Returns:\n","        - samples: Random samples from the distribution.\n","        \"\"\"\n","        if not isinstance(sample_shape, torch.Size):\n","            sample_shape = torch.Size(sample_shape)\n","\n","        with torch.no_grad():\n","            samples = torch.bernoulli(self.p.expand(sample_shape + self.p.size()))\n","            return samples\n","\n","\n","    def log_prob(self, value):\n","        \"\"\"\n","        Computes the log probability of a given value under the Bernoulli distribution.\n","\n","        Args:\n","        - value: Tensor of values for which log probabilities are computed.\n","\n","        Returns:\n","        - log_p: Log probabilities of the given values.\n","        \"\"\"\n","        log_p = value * torch.log(self.p + 1e-12) + (1 - value) * torch.log(1 - self.p + 1e-12)\n","        return log_p"]},{"cell_type":"markdown","metadata":{},"source":["## Define Modules\n","\n","Here we define different modules, to prepare different encoders and decoders for our experiments."]},{"cell_type":"code","execution_count":1750,"metadata":{},"outputs":[],"source":["class Clip(nn.Module):\n","    def __init__(self, x_min = -10, x_max = 10, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.x_min = x_min\n","        self.x_max = x_max\n","    \n","    def forward(self, x):\n","        return torch.clip(x, self.x_min, self.x_max)"]},{"cell_type":"code","execution_count":1751,"metadata":{},"outputs":[],"source":["RELU = \"relu\"\n","TANH = \"tanh\""]},{"cell_type":"code","execution_count":1752,"metadata":{},"outputs":[],"source":["class MultiPerceptron(nn.Module):\n","    def __init__(self, layer_sizes, activation: RELU or TANH = RELU, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","\n","        if activation == TANH:\n","            activation = nn.Tanh\n","        else:\n","            activation = nn.ReLU\n","\n","        layers = [nn.Identity()]\n","\n","        for i in range(1, len(layer_sizes)):\n","            layers.append(nn.Linear(layer_sizes[i-1], layer_sizes[i]))\n","            layers.append(activation())\n","\n","        # Create the Sequential module with all the layers\n","        self.mlp = nn.Sequential(*layers)\n","    \n","    def forward(self,x):\n","        return self.mlp(x)\n"]},{"cell_type":"code","execution_count":1753,"metadata":{},"outputs":[],"source":["class ToGaussParams(nn.Module):\n","    def __init__(self, input_size, output_size, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        \n","        self.to_mu = nn.Linear(in_features=input_size, out_features=output_size)\n","        self.to_logsigma2 = nn.Sequential(nn.Linear(in_features=input_size, out_features=output_size), Clip())\n","\n","    def forward(self, x):\n","        return self.to_mu(x), torch.sqrt(torch.exp(self.to_logsigma2(x)))\n","    \n","    "]},{"cell_type":"code","execution_count":1754,"metadata":{},"outputs":[],"source":["class ToGaussParams2(nn.Module):\n","    def __init__(self, input_size, output_size, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        \n","        self.to_mu = nn.Linear(in_features=input_size, out_features=output_size)\n","        logsigma_value = torch.zeros((1,))\n","        self.logsigma2 = nn.Parameter(logsigma_value)\n","\n","    def forward(self, x):\n","        return self.to_mu(x), torch.exp(self.logsigma2)\n","    \n","    "]},{"cell_type":"code","execution_count":1755,"metadata":{},"outputs":[],"source":["class GaussianCoder(nn.Module):\n","    def __init__(self, input_size, output_size, hidden_layers = [32,32], activation: RELU or TANH = RELU, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","\n","        self.mlp = MultiPerceptron(layer_sizes=[input_size] + hidden_layers, activation=activation)\n","\n","        self.to_gauss_params = ToGaussParams(input_size=hidden_layers[-1], output_size=output_size)\n","\n","    def forward(self, x):\n","        z = self.mlp(x)\n","        return self.to_gauss_params(z)"]},{"cell_type":"code","execution_count":1756,"metadata":{},"outputs":[],"source":["class BiaisBeforeWeight(nn.Module):\n","    def __init__(self, input_size, output_size, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","\n","        w_value = torch.randn(size=(input_size,output_size)) / np.sqrt(input_size*output_size)\n","\n","        b_value = torch.randn(size=(input_size,))\n","\n","        self.w = nn.Parameter(w_value)\n","\n","        self.b = nn.Parameter(b_value)\n","\n","    def forward(self, x):\n","        return (x - self.b) @ self.w\n"]},{"cell_type":"code","execution_count":1757,"metadata":{},"outputs":[],"source":["class Logits(nn.Module):\n","    def __init__(self, input_size, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","\n","        w_value = torch.randn(size=(input_size,)) / np.sqrt(input_size)\n","\n","        b_value = torch.randn(size=(input_size,)) / np.sqrt(input_size)\n","\n","        self.w = nn.Parameter(w_value)\n","\n","        self.b = nn.Parameter(b_value)\n","\n","    def forward(self, x):\n","        return  self.w * (x - self.b) "]},{"cell_type":"code","execution_count":1758,"metadata":{},"outputs":[],"source":["GAUSS = \"gauss\"\n","BERNOUILLI = \"bern\"\n","STUDENT = \"student\"\n","\n","\n","NOTMIWAE = \"not_miwae\"\n","MIWAE = \"miwae\""]},{"cell_type":"code","execution_count":1759,"metadata":{},"outputs":[],"source":["class PaperEncoder(nn.Module):\n","    def __init__(self,n_input, n_output, n_hidden = 100, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.mlp = MultiPerceptron([n_input,n_hidden,n_hidden],TANH)\n","        self.to_mu = nn.Linear(n_hidden,n_output)\n","        self.to_logsigma2 = nn.Sequential(nn.Linear(n_hidden,n_output),Clip())\n","    \n","    def forward(self,x):\n","        x = self.mlp(x)\n","        return self.to_mu(x), torch.exp(self.to_logsigma2(x))"]},{"cell_type":"code","execution_count":1760,"metadata":{},"outputs":[],"source":["class PaperDecoder(nn.Module):\n","    def __init__(self,n_input, n_output, n_hidden = 100, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.mlp = MultiPerceptron([n_input,n_hidden,n_hidden],TANH)\n","        self.to_mu = nn.Linear(n_hidden,n_output)\n","        self.to_sigma = nn.Sequential(nn.Linear(n_hidden,n_output), nn.Softplus())\n","    \n","    def forward(self,x):\n","        x = self.mlp(x)\n","        return self.to_mu(x), self.to_sigma(x)"]},{"cell_type":"code","execution_count":1761,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 20])\n"]}],"source":["class ConvolutionEncoder(nn.Module):\n","    def __init__(self, latent_dim = 20) -> None:\n","        super(ConvolutionEncoder, self,).__init__()\n","\n","        # Conv2D layer with input channels=1, output channels=64, kernel size=4, stride=2, padding=1\n","        self.conv1 = nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1)\n","        self.relu1 = nn.ReLU()\n","\n","        # Conv2D layer with input channels=64, output channels=128, kernel size=4, stride=2, padding=1\n","        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n","        self.relu2 = nn.ReLU()\n","\n","        # Conv2D layer with input channels=128, output channels=256, kernel size=4, stride=2, padding=1\n","        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1)\n","        self.relu3 = nn.ReLU()\n","\n","        # Reshape layer to flatten the output before fully connected layers\n","        self.reshape = nn.Flatten()\n","\n","        # Fully connected layers to generate Gaussian parameters (μ and log σ)\n","        self.to_gauss_params = ToGaussParams(4096, latent_dim)\n","\n","    def forward(self, x):\n","        # Input: (batch_size, 1, 32, 32)\n","        x = self.relu1(self.conv1(x))\n","        # Output: (batch_size, 64, 16, 16)\n","\n","        x = self.relu2(self.conv2(x))\n","        # Output: (batch_size, 128, 8, 8)\n","\n","        x = self.relu3(self.conv3(x))\n","        # Output: (batch_size, 256, 4, 4)\n","\n","        x = self.reshape(x)\n","        # Output: (batch_size, 4096)\n","\n","        return self.to_gauss_params(x)\n","\n","# Instantiate the model\n","model = ConvolutionEncoder()\n","\n","# Example input tensor with shape (batch_size, channels, height, width)\n","input_tensor = torch.randn(1, 1, 32, 32)\n","\n","# Forward pass\n","output_tensor = model(input_tensor)\n","\n","# Print the shape of the output tensor\n","print(output_tensor[0].shape)"]},{"cell_type":"code","execution_count":1762,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Output Shape: torch.Size([1, 1, 32, 32]) torch.Size([1, 1, 32, 32])\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","class ConvolutionDecoder(nn.Module):\n","    def __init__(self, latent_dim=20):\n","        super(ConvolutionDecoder, self).__init__()\n","\n","        # Latent variable z\n","        self.z_layer = nn.Linear(latent_dim, 4096)\n","        self.relu_z = nn.ReLU()\n","\n","        # Reshape to (256, 4, 4)\n","        self.reshape_layer = nn.Unflatten(-1, (256, 4, 4))\n","\n","        # Conv2Dtranspose layers\n","        self.conv_transpose1 = nn.ConvTranspose2d(256, 256, kernel_size=4, stride=2, padding=1)\n","        self.relu_conv1 = nn.ReLU()\n","\n","        self.conv_transpose2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1)\n","        self.relu_conv2 = nn.ReLU()\n","\n","        # μ layer\n","        self.mu_conv_transpose1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n","        self.relu_mu1 = nn.ReLU()\n","\n","        self.mu_conv_transpose2 = nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1)\n","        \n","\n","        # log σ layer\n","        self.logsigma_conv_transpose1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1)\n","        self.relu_logsigma1 = nn.ReLU()\n","\n","        self.logsigma_conv_transpose2 = nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1)\n","        self.clip = Clip(x_min= np.log(0.02))\n","        \n","\n","    def forward(self, z):\n","        # Latent variable z\n","        x = self.relu_z(self.z_layer(z))\n","        x = self.reshape_layer(x)\n","\n","        # Conv2Dtranspose layers\n","        x = self.relu_conv1(self.conv_transpose1(x))\n","        x = self.relu_conv2(self.conv_transpose2(x))\n","\n","        # μ layer\n","        mu = self.relu_mu1(self.mu_conv_transpose1(x))\n","        mu = self.mu_conv_transpose2(mu)\n","\n","        # log σ layer\n","        logsigma = self.relu_logsigma1(self.logsigma_conv_transpose1(x))\n","        logsigma = self.clip(self.logsigma_conv_transpose2(logsigma))\n","\n","        return torch.sigmoid(mu), torch.exp(logsigma)\n","\n","# Instantiate the generator model\n","latent_dim = 20\n","generator = ConvolutionDecoder(latent_dim)\n","\n","# Example input tensor with shape (batch_size, latent_dim)\n","input_tensor = torch.randn(1, latent_dim)\n","\n","# Forward pass through the generator\n","output = generator(input_tensor)\n","\n","# Print the shape of the output tensor\n","print(\"Output Shape:\", output[0].shape, output[1].shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["Ajouter d'autres méthodes inputation\n","\n","- k NN\n","- Multi inputation method Murray\n","- https://github.com/microsoft/EDDI"]},{"cell_type":"markdown","metadata":{},"source":["## Define notMIWAE"]},{"cell_type":"code","execution_count":1763,"metadata":{},"outputs":[],"source":["PAPER = 0\n","CONVOLUTIONAL  = 1 \n","LINEAR = 2"]},{"cell_type":"code","execution_count":1764,"metadata":{},"outputs":[],"source":["class notMIWAE_class(nn.Module):\n","    #Only Gaussian and Bern for the moment\n","    def __init__(self, input_size = 10, n_latent = 20, n_samples = 10, dist = GAUSS, architecture = PAPER, loss: NOTMIWAE or MIWAE = NOTMIWAE,):\n","        super(notMIWAE_class, self).__init__()\n","\n","        self.n_input = input_size\n","        self.n_latent = n_latent\n","        self.n_samples = n_samples\n","\n","        self.dist = dist\n","\n","        self.fix_x_sigma = False\n","\n","        self.architecture = architecture\n","        if True:\n","            self.encoder = PaperEncoder(n_input=self.n_input,\n","                                        n_output=self.n_latent,\n","                                        n_hidden=128)\n","\n","            self.decoder = ToGaussParams2(input_size= self.n_latent, output_size= self.n_input)\n","\n","        \n","        elif architecture == PAPER:\n","            self.encoder = PaperEncoder(n_input=self.n_input,\n","                                        n_output=self.n_latent,\n","                                        n_hidden=128)\n","\n","            self.decoder = PaperDecoder(n_input=self.n_latent,\n","                                        n_output=self.n_input,\n","                                        n_hidden=128)\n","            \n","        elif architecture == CONVOLUTIONAL:\n","            self.encoder = nn.Sequential(nn.Unflatten(1,(1,32,32)), ConvolutionEncoder(latent_dim=self.n_latent))\n","\n","            self.decoder = ConvolutionDecoder(latent_dim=self.n_latent)\n","\n","        elif architecture == LINEAR:\n","            # self.encoder = ToGaussParams(input_size=self.n_input, output_size= self.n_latent)\n","            self.encoder = PaperEncoder(n_input=self.n_input,\n","                                        n_output=self.n_latent,\n","                                        n_hidden=128)\n","\n","            self.decoder = ToGaussParams(input_size= self.n_latent, output_size= self.n_input)\n","        elif self.dist == GAUSS:\n","            self.encoder = GaussianCoder(input_size=self.n_input, output_size= self.n_latent)\n","\n","            self.decoder = GaussianCoder(input_size= self.n_latent, output_size= self.n_input)\n","        \n","        \n","\n","        if True:\n","            self.logits = Logits(input_size)\n","        else: \n","            self.logits = nn.Linear(in_features=input_size, out_features=input_size) # Logits(input_size) #, input_size) #nn.Linear(in_features=input_size, out_features=input_size)\n","\n","        self.sigma = torch.ones(n_latent)\n","\n","        self.prior = GaussDistribution(loc = 0., scale = 1.) # torch.distributions.normal.Normal(loc = 0., scale = 1.)\n","        \n","\n","\n","        if loss == NOTMIWAE:\n","            self.loss = lambda lpsx, lpxz, lpz, lpzx : - self.notmiwae(lpsx, lpxz, lpz, lpzx)\n","        elif loss == MIWAE:\n","            self.loss = lambda lpsx, lpxz, lpz, lpzx : - self.miwae(lpsx, lpxz, lpz, lpzx)\n","        else:\n","            print(\"Error\")\n","            print(f\"Only {NOTMIWAE} and {MIWAE} available.\")\n","\n","    \n","    def compute_log_probs(self, x, s, n_samples = None, return_x_samples = False):\n","        \"\"\"\n","        x : the input of size (batch, input_size)\n","        s : the mask of size (batch, input_size) s[i,j] = 1 if x[i,j] exists else 0\n","\n","        Return log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x of size (batch, n_sample, input_size)\n","        \"\"\"\n","        if n_samples is None:\n","            n_samples = self.n_samples\n","        \n","        if self.dist == GAUSS:\n","            z_mu, z_sigma = self.encoder(x) # (batch, n_latent), (batch, n_latent)\n","\n","            law_z_given_x = torch.distributions.normal.Normal(loc = z_mu, scale = z_sigma) # Distribution with parameter of size (batch, n_latent)\n","            # law_z_given_x = GaussDistribution(loc = z_mu, scale = z_sigma)\n","\n","        \n","        # Sampling and computing log_probs\n","        z_samples = law_z_given_x.rsample((n_samples,)) # (n_samples, batch, n_latent)\n","        log_prob_z_given_x = law_z_given_x.log_prob(z_samples).sum(dim=-1) # (n_samples, batch)\n","        \n","        # Transposing\n","        z_samples = z_samples.transpose(0,1) # (batch, n_samples, n_latent)\n","        log_prob_z_given_x = log_prob_z_given_x.transpose(0,1) # (batch, n_samples)\n","\n","        # Prior\n","        log_prob_z = self.prior.log_prob(z_samples).sum(dim=-1) # (batch, n_samples)\n","\n","        if self.dist == GAUSS:\n","            if self.architecture == CONVOLUTIONAL:\n","                n_batch = z_samples.size(0)\n","                z_samples =  z_samples.reshape(n_batch*n_samples, self.n_latent)\n","                # print(z_samples.size())\n","            x_mu, x_sigma = self.decoder(z_samples) # (batch, n_samples, input_size), (batch, n_samples, input_size)\n","\n","            if self.architecture == CONVOLUTIONAL:\n","                \n","                # print(x_mu.shape)\n","                x_mu = x_mu.reshape(n_batch, n_samples, self.n_input)\n","\n","                x_sigma = x_sigma.reshape(n_batch, n_samples, self.n_input)\n","                # print(x_mu.size())\n","            # Issue of stability\n","            if self.fix_x_sigma:\n","                x_sigma = 1  # (batch, n_samples, input_size)\n","\n","            law_x_given_z = torch.distributions.normal.Normal(loc = x_mu, scale = x_sigma) # Distribution with parameter of size (batch, n_samples, input_size)\n","            # law_x_given_z = GaussDistribution(loc = x_mu, scale = x_sigma) # Distribution with parameter of size (batch, n_samples, input_size)\n","\n","        # Sampling and computing log_probs of the observed input\n","        x_samples  = law_x_given_z.rsample() # (batch, n_samples, input_size)\n","        log_prob_x_given_z = (law_x_given_z.log_prob(x.unsqueeze(1)) * s.unsqueeze(1)).sum(dim=-1) # (batch, n_samples)\n","\n","        \n","        \n","        # Missing mechanism\n","        # We recreate the x_sample using the real x we know (x_o) and the x_samples we created from z (x_m).\n","        mixed_x_samples = x_samples * (1-s).unsqueeze(1) + (x*s).unsqueeze(1) # (batch, n_samples, input_size)\n","\n","        logits = self.logits(mixed_x_samples) # (batch, n_samples, input_size)\n","        \n","        law_s_given_x = BernoulliDistribution(logits=logits) # Distribution with parameter of size (batch, n_samples, input_size)\n","        # law_s_given_x = torch.distributions.bernoulli.Bernoulli(logits=logits)\n","\n","\n","        log_prob_s_given_x = law_s_given_x.log_prob(s.unsqueeze(1)).sum(dim=-1) # (batch, n_samples)\n","\n","        if return_x_samples:\n","            return log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x, x_samples # 4x(batch, n_samples), (batch, n_samples, input_size)\n","        else:\n","            return log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x # (batch, n_samples)\n","    \n","    def compute_loss(self, x, s):\n","                        \n","        return self.loss(*self.compute_log_probs(x,s))\n","    \n","    def compute_loss2(self, x, s):\n","        pass\n","    \n","    def rmse_imputation_fast(self, x_orginal, x, s, nb_samples = 1_000):\n","        \"\"\"\n","        Return the rmse on the missing data and x with the missing values \n","        \"\"\"\n","\n","        x = torch.FloatTensor(x)\n","        s = torch.FloatTensor(s)\n","        x_orginal = torch.FloatTensor(x_orginal)\n","\n","        \n","        with torch.no_grad():\n","            log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x, x_samples = self.compute_log_probs(x,s,return_x_samples=True, n_samples=nb_samples) # 4x(batch, n_samples), (batch, n_samples, input_size)\n","\n","            aks = torch.softmax(log_prob_s_given_x + log_prob_x_given_z + log_prob_z - log_prob_z_given_x, dim = 1) # (batch,n_samples)\n","\n","            xm = torch.sum(aks.unsqueeze(-1)* x_samples, dim = 1)\n","\n","            x_mixed = x * s + (1-s) * xm\n","\n","            rmse = torch.sqrt(torch.sum(((x_orginal - xm) * (1 - s))**2) / torch.sum(1 - s))\n","\n","            # rmse2 = torch.sqrt(torch.sum(((x_orginal - x_mixed) **2 * (1 - s))) / torch.sum(1 - s))\n","            # print( f'{rmse} =? {rmse2}')\n","            return rmse, x_mixed\n","    \n","    def rmse_imputation(self, x_orginal, x, s, nb_samples = 1_000):\n","        \"\"\"\n","        Return the rmse on the missing data and x with the missing values \n","        \"\"\"\n","\n","        x = torch.FloatTensor(x)\n","        s = torch.FloatTensor(s)\n","        x_orginal = torch.FloatTensor(x_orginal)\n","\n","        x_mixed = np.zeros_like(x_orginal)\n","        N = x_orginal.size(0)\n","        with torch.no_grad():\n","            for i in range(N):\n","                x_batch = x[i,:].unsqueeze(0)\n","                s_batch = s[i,:].unsqueeze(0)\n","                log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x, x_samples = self.compute_log_probs(x_batch,s_batch ,return_x_samples=True, n_samples=nb_samples) # 4x(batch, n_samples), (batch, n_samples, input_size)\n","\n","                aks = torch.softmax(log_prob_s_given_x + log_prob_x_given_z + log_prob_z - log_prob_z_given_x, dim = 1) # (batch,n_samples)\n","\n","                xm = torch.sum(aks.unsqueeze(-1)* x_samples, dim = 1)\n","\n","                x_mixed[i,:] = x_batch * s_batch + (1-s_batch) * xm\n","\n","            rmse = torch.sqrt(torch.sum(((x_orginal - x_mixed) * (1 - s))**2) / torch.sum(1 - s))\n","\n","                # rmse2 = torch.sqrt(torch.sum(((x_orginal - x_mixed) **2 * (1 - s))) / torch.sum(1 - s))\n","                # print( f'{rmse} =? {rmse2}')\n","            return rmse, x_mixed\n","    \n","    def rmse_imputation_with_batch(self, x_orginal, x, s, batch =64):\n","        \"\"\"\n","        Return the rmse on the missing data and x with the missing values \n","        \"\"\"\n","\n","        x = torch.FloatTensor(x)\n","        s = torch.FloatTensor(s)\n","        x_orginal = torch.FloatTensor(x_orginal)\n","\n","        N = x.size(0)\n","\n","        squared_error = 0.\n","        number_missing = 0\n","        with torch.no_grad():\n","            for i in range(0,N,batch_size):\n","                X_batch = x[i:(i+batch_size)]\n","                S_batch = s[i:(i+batch_size)]\n","                X_orginal_batch = x_orginal[i:(i+batch_size)]\n","                log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x, x_samples = self.compute_log_probs(X_batch,S_batch,return_x_samples=True) # 4x(batch, n_samples), (batch, n_samples, input_size)\n","\n","                aks = torch.softmax(log_prob_s_given_x + log_prob_x_given_z + log_prob_z - log_prob_z_given_x, dim = 1) # (batch,n_samples)\n","\n","                xm = torch.sum(aks.unsqueeze(-1)* x_samples, dim = 1)\n","\n","                x_mixed = x * s + (1-s) * xm\n","\n","                squared_error += torch.sum(((X_orginal_batch - X_batch) * (1 - s))**2) \n","                number_missing += torch.sum(1 - S_batch)\n","            # rmse2 = torch.sqrt(torch.sum(((x_orginal - x_mixed) **2 * (1 - s))) / torch.sum(1 - s))\n","            # print( f'{rmse} =? {rmse2}')\n","            return torch.sqrt(squared_error/number_missing)\n","    def rmse_imputation_miwae(self, x_orginal, x, s):\n","        \"\"\"\n","        Return the rmse on the missing data and x with the missing values \n","        \"\"\"\n","\n","        x = torch.FloatTensor(x)\n","        s = torch.FloatTensor(s)\n","        x_orginal = torch.FloatTensor(x_orginal)\n","\n","        \n","        with torch.no_grad():\n","            log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x, x_samples = self.compute_log_probs(x,s,return_x_samples=True) # 4x(batch, n_samples), (batch, n_samples, input_size)\n","\n","            aks = torch.softmax( log_prob_x_given_z + log_prob_z - log_prob_z_given_x, dim = 1) # (batch,n_samples)\n","\n","            xm = torch.sum(aks.unsqueeze(-1)* x_samples, dim = 1)\n","\n","            x_mixed = x * s + (1-s) * xm\n","\n","            rmse = torch.sqrt(torch.sum(((x_orginal - xm) * (1 - s))**2) / torch.sum(1 - s))\n","\n","            # rmse2 = torch.sqrt(torch.sum(((x_orginal - x_mixed) **2 * (1 - s))) / torch.sum(1 - s))\n","            # print( f'{rmse} =? {rmse2}')\n","            return rmse, x_mixed\n","\n","\n","\n","    def fit(self, X, S,\n","             batch_size = 100,\n","             epochs = 60,\n","             lr = 0.01,\n","             verbose = False):\n","        \n","        X = torch.FloatTensor(X)\n","        S = torch.FloatTensor(S)\n","        N = X.size(0)\n","        \n","        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n","        for epoch in range(epochs):\n","            if verbose:\n","                print(f'Epochs:{epoch+1}')\n","            p = np.random.permutation(N)\n","            X = X[p,:]\n","            S = S[p,:]\n","            \n","            for i in range(0,N,batch_size):\n","                if verbose:\n","                    print(f'{i+batch_size} / {N}', end=\"\\r\")\n","                X_batch = X[i:(i+batch_size)]\n","                S_batch = S[i:(i+batch_size)]\n","                        \n","                elbo = self.compute_loss(X_batch,S_batch)\n","                \n","                optimizer.zero_grad()\n","                elbo.backward()\n","                optimizer.step()\n","                \n","            if verbose:\n","                with torch.no_grad():\n","                    print('loss', self.compute_loss(X,S).item())\n","            for param in self.parameters():\n","                if torch.isnan(param).any().item():\n","                    print('NaN parameter')\n","                    print(torch.isnan(param).any().item())\n","        if verbose:\n","            print(f'final_loss = {self.compute_loss(X,S).item()}')\n","    \n","    # law_z_given_x2 = torch.distributions.normal.Normal(loc=z_mu.unsqueeze(0), scale=z_sigma.unsqueeze(0))\n","\n","    def miwae(self, log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x):\n","\n","        log_sum_w = torch.logsumexp( log_prob_x_given_z + log_prob_z - log_prob_z_given_x, dim = 1) # (batch)\n","        log_mean_w = log_sum_w - torch.log(torch.Tensor([self.n_samples])) # (batch)\n","\n","        return log_mean_w.mean()\n","    \n","    def notmiwae(self, log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x):\n","\n","        log_sum_w = torch.logsumexp( log_prob_s_given_x + log_prob_x_given_z + log_prob_z - log_prob_z_given_x, dim = 1) # (batch)\n","        log_mean_w = log_sum_w - torch.log(torch.Tensor([self.n_samples])) # (batch)\n","\n","        return log_mean_w.mean()\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# not-MIWAE: Deep Generative Modelling with Missing not at Random Data\n","This notebook illustrates how to fit a *deep latent variable model* to data affected by a missing process which depends on the missing data itself, i.e. *missing not at random*.\n","\n","We fit a linear PPCA-like model to a relatively small UCI dataset."]},{"cell_type":"markdown","metadata":{},"source":["### Preamble"]},{"cell_type":"code","execution_count":1765,"metadata":{},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","import keras\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import time\n","\n","# import sys\n","# sys.path.append('./')\n","\n","import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n","\n","plt.rcParams[\"font.family\"] = \"serif\"\n","plt.rcParams['font.size'] = 15.0\n","plt.rcParams['axes.spines.right'] = False\n","plt.rcParams['axes.spines.top'] = False\n","plt.rcParams['savefig.format'] = 'pdf'\n","plt.rcParams['lines.linewidth'] = 2.5\n"]},{"cell_type":"markdown","metadata":{},"source":["### Load data\n","Here we use the white-wine dataset from the UCI database"]},{"cell_type":"code","execution_count":1766,"metadata":{"collapsed":true},"outputs":[],"source":["url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n","data = np.array(pd.read_csv(url, low_memory=False, sep=';'))\n","# ---- drop the classification attribute\n","data = data[:, :-1]"]},{"cell_type":"markdown","metadata":{},"source":["### Settings"]},{"cell_type":"code","execution_count":1767,"metadata":{"collapsed":true},"outputs":[],"source":["N, D = data.shape\n","n_latent = D - 1\n","n_hidden = 128\n","n_samples = 3\n","max_iter = 30000\n","batch_size = 16"]},{"cell_type":"markdown","metadata":{},"source":["### Standardize data"]},{"cell_type":"code","execution_count":1768,"metadata":{"collapsed":true},"outputs":[],"source":["# ---- standardize data\n","data = data - np.mean(data, axis=0)\n","data = data / np.std(data, axis=0)\n","\n","# ---- random permutation\n","p = np.random.permutation(N)\n","data = data[p, :]\n","\n","# ---- we use the full dataset for training here, but you can make a train-val split\n","Xtrain = data.copy()\n","Xval = Xtrain.copy()"]},{"cell_type":"markdown","metadata":{},"source":["### Introduce missing \n","Here we denote\n","- Xnan: data matrix with np.nan as the missing entries\n","- Xz: data matrix with 0 as the missing entries\n","- S: missing mask \n","\n","The missing process depends on the missing data itself:\n","- in half the features, set the feature value to missing when it is higher than the feature mean"]},{"cell_type":"code","execution_count":1769,"metadata":{"collapsed":true},"outputs":[],"source":["# ---- introduce missing process\n","Xnan = Xtrain.copy()\n","Xz = Xtrain.copy()\n","\n","mean = np.mean(Xnan[:, :int(D / 2)], axis=0)\n","ix_larger_than_mean = Xnan[:, :int(D / 2)] > mean\n","\n","Xnan[:, :int(D / 2)][ix_larger_than_mean] = np.nan\n","Xz[:, :int(D / 2)][ix_larger_than_mean] = 0\n","\n","S = np.array(~np.isnan(Xnan), dtype=np.float32)"]},{"cell_type":"markdown","metadata":{},"source":["### Build the model\n","The model we are building has a Gaussian prior and a Gaussian observation model,\n","\n","$$ p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{z} | \\mathbf{0}, \\mathbf{I})$$\n","\n","$$ p(\\mathbf{x} | \\mathbf{z}) = \\mathcal{N}(\\mathbf{x} | \\mathbf{\\mu}_{\\theta}(\\mathbf{z}), \\sigma^2\\mathbf{I})$$\n","\n","$$ p(\\mathbf{x}) = \\int p(\\mathbf{x} | \\mathbf{z})p(\\mathbf{z}) d\\mathbf{z}$$\n","\n","where $\\mathbf{\\mu}_{\\theta}(\\mathbf{z}): \\mathbb{R}^d \\rightarrow \\mathbb{R}^p $ in general is a deep neural net, but in this case is a linear mapping, $\\mathbf{\\mu} = \\mathbf{Wz + b}$.\n","\n","The variational posterior is also Gaussian\n","\n","$$q_{\\gamma}(\\mathbf{z} | \\mathbf{x}) = \\mathcal{N}(\\mathbf{z} | \\mu_{\\gamma}(\\mathbf{x}), \\sigma_{\\gamma}(\\mathbf{x})^2 \\mathbf{I})$$\n","\n","If the missing process is *missing at random*, it is ignorable and the ELBO becomes, as described in [the MIWAE paper](https://arxiv.org/abs/1812.02633)\n","\n","$$ E_{\\mathbf{z}_1...\\mathbf{z}_K} \\left[ \\log \\frac{1}{K}\\sum_{k=1}^K \\frac{p_{\\theta}(\\mathbf{x^o} | \\mathbf{z}_k)p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z}_k | \\mathbf{x^o})} \\right] $$\n","\n","When the missing process is MNAR it is non-ignorable and we need to include the missing model. In this example we include the missing model as a logistic regression in each feature dimension\n","\n","$$ p_{\\phi}(\\mathbf{s} | \\mathbf{x^o, x^m}) = \\text{Bern}(\\mathbf{s} | \\pi_{\\phi}(\\mathbf{x^o, x^m}))$$\n","\n","$$ \\pi_{\\phi, j}(x_j) = \\frac{1}{1 + e^{-\\text{logits}_j}} $$\n","\n","$$ \\text{logits}_j = W_j (x_j - b_j) $$\n","\n","The ELBO in the MNAR case becomes\n","\n","$$ E_{(\\mathbf{z}_1, \\mathbf{x}_1^m)...(\\mathbf{z}_K, \\mathbf{x}_K^m)} \\left[ \\log \\frac{1}{K} \\sum_{k=1}^K \\frac{p_{\\phi}(\\mathbf{s} | \\mathbf{x}^o, \\mathbf{x}_k^m) p_{\\theta}(\\mathbf{x}^o | \\mathbf{z}_k) p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z} | \\mathbf{x}^o)} \\right]$$\n"]},{"cell_type":"markdown","metadata":{},"source":["# EPSILON"]},{"cell_type":"code","execution_count":1770,"metadata":{},"outputs":[],"source":["EPS1_pytorch = torch.randn((3,1,n_latent))\n","EPS1_array = EPS1_pytorch.numpy()\n","\n","disttt = torch.distributions.normal.Normal(0,1)\n","lpzx_mano = disttt.log_prob(EPS1_pytorch).sum(dim = - 1)"]},{"cell_type":"markdown","metadata":{},"source":["### Inputs\n","Let's first define the inputs of the model\n","- x_pl: data input\n","- s_pl: mask input\n","- n_pl: number of importance samples"]},{"cell_type":"code","execution_count":1771,"metadata":{},"outputs":[],"source":["tf.compat.v1.disable_eager_execution()"]},{"cell_type":"code","execution_count":1772,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating graph...\n"]}],"source":["print(\"Creating graph...\")\n","tf.compat.v1.reset_default_graph()\n","# ---- input\n","with tf.compat.v1.variable_scope('input'):\n","    x_pl = tf.compat.v1.placeholder(tf.float32, [None, D], 'x_pl')\n","    s_pl = tf.compat.v1.placeholder(tf.float32, [None, D], 's_pl')\n","    n_pl = tf.compat.v1.placeholder(tf.int32, shape=(), name='n_pl')"]},{"cell_type":"markdown","metadata":{},"source":["the noise variance is learned as a shared parameter"]},{"cell_type":"code","execution_count":1773,"metadata":{},"outputs":[],"source":["# ---- parameters\n","with tf.compat.v1.variable_scope('data_process'):\n","    logstd = tf.compat.v1.get_variable('logstd', shape=[])"]},{"cell_type":"markdown","metadata":{},"source":["### Encoder\n","The encoder / inference network consists of two hidden layers with 128 units and tanh activation"]},{"cell_type":"code","execution_count":1774,"metadata":{},"outputs":[],"source":["x = keras.layers.Dense(units=n_hidden, activation=tf.nn.tanh, name='l_enc1')(x_pl)\n","x = keras.layers.Dense(units=n_hidden, activation=tf.nn.tanh, name='l_enc2')(x)\n","\n","q_mu = keras.layers.Dense(units=n_latent, activation=None, name='q_mu')(x)\n","\n","q_logstd = keras.layers.Dense(units=n_latent, activation=lambda x: tf.clip_by_value(x, -10, 10),\n","                           name='q_logstd')(x)"]},{"cell_type":"markdown","metadata":{},"source":["### Variational distribution"]},{"cell_type":"code","execution_count":1775,"metadata":{"collapsed":true},"outputs":[],"source":["q_z = tfp.distributions.Normal(loc=q_mu, scale=tf.exp(q_logstd))\n","\n","# ---- sample the latent value\n","# l_z = q_z.sample(n_pl)                    # shape [n_samples, batch_size, dl]\n","l_z = q_mu + tf.exp(q_logstd) * EPS1_array\n","l_z = tf.transpose(l_z, perm=[1, 0, 2])   # shape [batch_size, n_samples, dl]"]},{"cell_type":"markdown","metadata":{},"source":["### Decoder"]},{"cell_type":"code","execution_count":1776,"metadata":{"collapsed":true},"outputs":[],"source":["mu = keras.layers.Dense(units=D, activation=None, name='mu')(l_z)"]},{"cell_type":"markdown","metadata":{},"source":["### Observation model / likelihood function"]},{"cell_type":"code","execution_count":1777,"metadata":{"collapsed":true},"outputs":[],"source":["p_x_given_z = tfp.distributions.Normal(loc=mu, scale=tf.exp(logstd))"]},{"cell_type":"markdown","metadata":{},"source":["### Missing model\n","- first mix observed data and samples of missing data\n","- feed through missing model\n","- find likelihood of missing model parameters\n","\n","We have to expand the dimensions of x_pl and s_pl, since mu has size [batch, n_samples, D]"]},{"cell_type":"code","execution_count":1778,"metadata":{"collapsed":true},"outputs":[],"source":["l_out_mixed = mu * tf.expand_dims(1 - s_pl, axis=1) + tf.expand_dims(x_pl * s_pl, axis=1)"]},{"cell_type":"code","execution_count":1779,"metadata":{"collapsed":true},"outputs":[],"source":["W = tf.compat.v1.get_variable('W', shape=[1, 1, D])\n","# W = -tf.nn.softplus(W)\n","b = tf.compat.v1.get_variable('b', shape=[1, 1, D])\n","\n","logits = W * (l_out_mixed - b)\n","\n","p_s_given_x = tfp.distributions.Bernoulli(logits=logits)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluating likelihoods"]},{"cell_type":"code","execution_count":1780,"metadata":{},"outputs":[],"source":["# ---- evaluate the observed data in p(x|z)\n","log_p_x_given_z = tf.reduce_sum(tf.expand_dims(s_pl, axis=1) *\n","                                p_x_given_z.log_prob(tf.expand_dims(x_pl, axis=1)), axis=-1)  # sum over d-dimension\n","\n","# --- evaluate the z-samples in q(z|x)\n","q_z2 = tfp.distributions.Normal(loc=tf.expand_dims(q_z.loc, axis=1), scale=tf.expand_dims(q_z.scale, axis=1))\n","log_q_z_given_x = tf.reduce_sum(q_z2.log_prob(l_z), axis=-1)\n","\n","# ---- evaluate the z-samples in the prior p(z)\n","prior = tfp.distributions.Normal(loc=0.0, scale=1.0)\n","log_p_z = tf.reduce_sum(prior.log_prob(l_z), axis=-1)\n","\n","# ---- evaluate the mask in p(s|x)\n","log_p_s_given_x = tf.reduce_sum(p_s_given_x.log_prob(tf.expand_dims(s_pl, axis=1)), axis=-1)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Losses for the MIWAE and not-MIWAE respectively"]},{"cell_type":"code","execution_count":1781,"metadata":{"collapsed":true},"outputs":[],"source":["lpxz = log_p_x_given_z\n","lpz = log_p_z\n","lqzx = log_q_z_given_x\n","lpsx = log_p_s_given_x\n","\n","# ---- MIWAE\n","# ---- importance weights\n","l_w = lpxz + lpz - lqzx\n","\n","# ---- sum over samples\n","log_sum_w = tf.reduce_logsumexp(l_w, axis=1)\n","\n","# ---- average over samples\n","log_avg_weight = log_sum_w - tf.math.log(tf.cast(n_pl, tf.float32))\n","\n","# ---- average over minibatch to get the average llh\n","MIWAE = tf.reduce_mean(log_avg_weight, axis=-1)\n","\n","\n","# ---- not-MIWAE\n","# ---- importance weights\n","l_w = lpxz + lpsx + lpz - lqzx\n","\n","# ---- sum over samples\n","log_sum_w = tf.reduce_logsumexp(l_w, axis=1)\n","\n","# ---- average over samples\n","log_avg_weight = log_sum_w - tf.math.log(tf.cast(n_pl, tf.float32))\n","\n","# ---- average over minibatch to get the average llh\n","notMIWAE = tf.reduce_mean(log_avg_weight, axis=-1)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training stuff"]},{"cell_type":"code","execution_count":1782,"metadata":{"collapsed":true},"outputs":[],"source":["# ---- training stuff\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True\n","sess = tf.compat.v1.Session(config=config)\n","global_step = tf.Variable(initial_value=0, trainable=False)\n","optimizer = tf.compat.v1.train.AdamOptimizer()"]},{"cell_type":"markdown","metadata":{},"source":["### Choose wether you want to train the MIWAE or the notMIWAE"]},{"cell_type":"code","execution_count":1783,"metadata":{"collapsed":true},"outputs":[],"source":["loss = -notMIWAE\n","# loss = -MIWAE\n","\n","tvars = tf.compat.v1.trainable_variables()\n","train_op = optimizer.minimize(loss, global_step=global_step, var_list=tvars)\n","sess.run(tf.compat.v1.global_variables_initializer())"]},{"cell_type":"code","execution_count":1784,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Variable Name: data_process/logstd:0, Shape: (), Value: <tf.Variable 'data_process/logstd:0' shape=() dtype=float32>\n","Variable Name: l_enc1/kernel:0, Shape: (11, 128), Value: <tf.Variable 'l_enc1/kernel:0' shape=(11, 128) dtype=float32>\n","Variable Name: l_enc1/bias:0, Shape: (128,), Value: <tf.Variable 'l_enc1/bias:0' shape=(128,) dtype=float32>\n","Variable Name: l_enc2/kernel:0, Shape: (128, 128), Value: <tf.Variable 'l_enc2/kernel:0' shape=(128, 128) dtype=float32>\n","Variable Name: l_enc2/bias:0, Shape: (128,), Value: <tf.Variable 'l_enc2/bias:0' shape=(128,) dtype=float32>\n","Variable Name: q_mu/kernel:0, Shape: (128, 10), Value: <tf.Variable 'q_mu/kernel:0' shape=(128, 10) dtype=float32>\n","Variable Name: q_mu/bias:0, Shape: (10,), Value: <tf.Variable 'q_mu/bias:0' shape=(10,) dtype=float32>\n","Variable Name: q_logstd/kernel:0, Shape: (128, 10), Value: <tf.Variable 'q_logstd/kernel:0' shape=(128, 10) dtype=float32>\n","Variable Name: q_logstd/bias:0, Shape: (10,), Value: <tf.Variable 'q_logstd/bias:0' shape=(10,) dtype=float32>\n","Variable Name: mu/kernel:0, Shape: (10, 11), Value: <tf.Variable 'mu/kernel:0' shape=(10, 11) dtype=float32>\n","Variable Name: mu/bias:0, Shape: (11,), Value: <tf.Variable 'mu/bias:0' shape=(11,) dtype=float32>\n","Variable Name: W:0, Shape: (1, 1, 11), Value: <tf.Variable 'W:0' shape=(1, 1, 11) dtype=float32>\n","Variable Name: b:0, Shape: (1, 1, 11), Value: <tf.Variable 'b:0' shape=(1, 1, 11) dtype=float32>\n","Value of the first variable: [[ 0.0983675   0.02060916 -0.20272103 ...  0.16320227 -0.03432383\n","  -0.00287151]\n"," [-0.06588101 -0.06674945 -0.13445833 ...  0.04959415 -0.08132237\n","  -0.09817849]\n"," [ 0.05380048  0.07554744  0.04904921 ... -0.17382088 -0.10487645\n","   0.20112388]\n"," ...\n"," [ 0.03319371 -0.19980384  0.06265755 ...  0.10818352 -0.12330712\n","   0.04550387]\n"," [ 0.20425452 -0.06293014  0.19029419 ...  0.05095963 -0.05076842\n","  -0.06635089]\n"," [-0.0129094   0.12863411  0.20517121 ... -0.04153913  0.20095299\n","  -0.11777555]]\n"]}],"source":["# Get the list of trainable variables\n","trainable_variables = tf.compat.v1.trainable_variables()\n","\n","# Print the names and shapes of the variables\n","for var in trainable_variables:\n","    print(f\"Variable Name: {var.name}, Shape: {var.shape}, Value: {var}\")\n","\n","# Get the values of the variables\n","variable_values = sess.run(trainable_variables)\n","\n","# Access a specific variable's value (e.g., the first variable)\n","first_variable_value = variable_values[1]\n","print(f\"Value of the first variable: {first_variable_value}\")\n","\n","named_variables = zip([var.name for var in trainable_variables],variable_values )"]},{"cell_type":"code","execution_count":1785,"metadata":{},"outputs":[],"source":["notmiwae = notMIWAE_class(D,n_latent=n_latent, n_samples=n_samples,architecture=LINEAR)"]},{"cell_type":"code","execution_count":1786,"metadata":{},"outputs":[{"data":{"text/plain":["notMIWAE_class(\n","  (encoder): PaperEncoder(\n","    (mlp): MultiPerceptron(\n","      (mlp): Sequential(\n","        (0): Identity()\n","        (1): Linear(in_features=11, out_features=128, bias=True)\n","        (2): Tanh()\n","        (3): Linear(in_features=128, out_features=128, bias=True)\n","        (4): Tanh()\n","      )\n","    )\n","    (to_mu): Linear(in_features=128, out_features=10, bias=True)\n","    (to_logsigma2): Sequential(\n","      (0): Linear(in_features=128, out_features=10, bias=True)\n","      (1): Clip()\n","    )\n","  )\n","  (decoder): ToGaussParams2(\n","    (to_mu): Linear(in_features=10, out_features=11, bias=True)\n","  )\n","  (logits): Logits()\n",")"]},"execution_count":1786,"metadata":{},"output_type":"execute_result"}],"source":["notmiwae"]},{"cell_type":"code","execution_count":1787,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["encoder.mlp.mlp.1.weight torch.Size([128, 11])\n","encoder.mlp.mlp.1.bias torch.Size([128])\n","encoder.mlp.mlp.3.weight torch.Size([128, 128])\n","encoder.mlp.mlp.3.bias torch.Size([128])\n","encoder.to_mu.weight torch.Size([10, 128])\n","encoder.to_mu.bias torch.Size([10])\n","encoder.to_logsigma2.0.weight torch.Size([10, 128])\n","encoder.to_logsigma2.0.bias torch.Size([10])\n","decoder.logsigma2 torch.Size([1])\n","decoder.to_mu.weight torch.Size([11, 10])\n","decoder.to_mu.bias torch.Size([11])\n","logits.w torch.Size([11])\n","logits.b torch.Size([11])\n"]}],"source":["for name,param in notmiwae.named_parameters():\n","    print(name,param.shape)"]},{"cell_type":"code","execution_count":1788,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 data_process/logstd:0 1.4880913\n","1 l_enc1/kernel:0 [[ 0.0983675   0.02060916 -0.20272103 ...  0.16320227 -0.03432383\n","  -0.00287151]\n"," [-0.06588101 -0.06674945 -0.13445833 ...  0.04959415 -0.08132237\n","  -0.09817849]\n"," [ 0.05380048  0.07554744  0.04904921 ... -0.17382088 -0.10487645\n","   0.20112388]\n"," ...\n"," [ 0.03319371 -0.19980384  0.06265755 ...  0.10818352 -0.12330712\n","   0.04550387]\n"," [ 0.20425452 -0.06293014  0.19029419 ...  0.05095963 -0.05076842\n","  -0.06635089]\n"," [-0.0129094   0.12863411  0.20517121 ... -0.04153913  0.20095299\n","  -0.11777555]]\n","2 l_enc1/bias:0 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0.]\n","3 l_enc2/kernel:0 [[-0.00654405 -0.01062818  0.05340938 ... -0.05688333 -0.05118652\n","   0.04640038]\n"," [-0.03822937 -0.15046981 -0.07360996 ...  0.01191145  0.10948966\n","  -0.09334141]\n"," [-0.10059547  0.12730412  0.00786152 ... -0.06599682 -0.12754758\n","  -0.04196079]\n"," ...\n"," [-0.05401273 -0.04927157  0.03828058 ...  0.09688559  0.00191067\n","  -0.02434216]\n"," [-0.086734    0.07229468  0.13095097 ...  0.10961176 -0.06658021\n","  -0.1348549 ]\n"," [-0.07087873  0.08536823 -0.09397729 ...  0.04053663 -0.02125545\n","   0.0531856 ]]\n","4 l_enc2/bias:0 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0.]\n","5 q_mu/kernel:0 [[-0.04186809  0.04678641  0.05079229 ...  0.11181428  0.1756071\n","   0.1313134 ]\n"," [-0.03497851 -0.09646085  0.16506909 ... -0.01874843  0.06256361\n","   0.04266424]\n"," [-0.01598345  0.03312191 -0.09942011 ... -0.09288669  0.16888832\n","  -0.12072313]\n"," ...\n"," [ 0.09098379  0.06304838 -0.09869787 ... -0.01115754  0.19466998\n","   0.18716316]\n"," [ 0.18921332 -0.20014739 -0.20403983 ...  0.1724842   0.05049266\n","   0.01610799]\n"," [ 0.07804461  0.12106238  0.19430633 ...  0.01221347  0.0713336\n","  -0.12237581]]\n","6 q_mu/bias:0 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","7 q_logstd/kernel:0 [[-0.11281338  0.14324377  0.1736718  ... -0.13401891 -0.10642771\n","  -0.01916359]\n"," [-0.01301609  0.18762167 -0.12336735 ... -0.06832667  0.00507373\n","   0.18876465]\n"," [ 0.12798055  0.2061976   0.01838283 ...  0.12837167 -0.08496112\n","   0.16415472]\n"," ...\n"," [ 0.18282051 -0.12129354  0.17916323 ... -0.11949008 -0.0088992\n","   0.00306833]\n"," [-0.12237666 -0.04168773  0.06123148 ... -0.02332394 -0.11473159\n","   0.2014047 ]\n"," [-0.05240212  0.12672679 -0.10923534 ...  0.19132431 -0.20562549\n","   0.07255583]]\n","8 q_logstd/bias:0 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","9 mu/kernel:0 [[-0.03962991  0.35421157 -0.2647703  -0.00882334 -0.09542421 -0.25193885\n","  -0.02299249  0.1024217   0.39377075  0.28238314  0.45852613]\n"," [ 0.45596647 -0.50110245  0.05230242 -0.43770814 -0.20922196 -0.3241979\n","   0.184161    0.18896854  0.37387073  0.25434238 -0.14828318]\n"," [ 0.4687087   0.37524873  0.23377281 -0.10763833  0.19449371  0.42682528\n","   0.30962294  0.0587703  -0.07042888 -0.41783896 -0.5235778 ]\n"," [-0.09853169 -0.01455784  0.06924748  0.5265282  -0.5058543  -0.37573212\n","  -0.09565297  0.35584152  0.13346815  0.43805707 -0.19125965]\n"," [ 0.1194669  -0.06185025  0.08203    -0.43040138  0.32277542  0.25063312\n","  -0.52516633 -0.02626568 -0.37204796 -0.2877015   0.40051323]\n"," [-0.43876475 -0.14382124 -0.27141106 -0.42819232 -0.2240681  -0.30984586\n","  -0.17397344  0.16329867  0.12655783 -0.04490325  0.02372783]\n"," [-0.2719299  -0.18471423 -0.13738999 -0.49628395  0.17078602 -0.07739374\n","  -0.36848384 -0.2520194  -0.34577784  0.16015881  0.3835011 ]\n"," [-0.44726107  0.5063173   0.09465653 -0.08206147 -0.16643447  0.16977441\n","  -0.51716644  0.47032148 -0.09653687  0.28047693 -0.32035977]\n"," [ 0.0854826  -0.38962895  0.10005319 -0.3104025  -0.41113168  0.21017289\n","  -0.3985235  -0.1799765   0.2973979   0.46500838  0.13554424]\n"," [-0.25012627 -0.44013053 -0.29896462 -0.19715428 -0.07173666  0.31060755\n","  -0.21570751  0.39187676  0.21000838 -0.4307684  -0.3440054 ]]\n","10 mu/bias:0 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","11 W:0 [[[ 0.21650213  0.08470267 -0.59822273 -0.26080504  0.04995292\n","    0.15488797 -0.527308   -0.4140995   0.6027549  -0.6438752\n","   -0.42827788]]]\n","12 b:0 [[[ 0.63505894 -0.38608652 -0.44613013  0.19625866 -0.69011015\n","    0.10894066 -0.26972196  0.20977885  0.34181637 -0.40618992\n","    0.31432027]]]\n"]}],"source":["for i, (name, value) in enumerate(named_variables):\n","    print(i, (name),value)\n","    if i == 0:\n","        notmiwae.decoder.logsigma2.data = torch.tensor(value)\n","    if i == 1:\n","        notmiwae.encoder.mlp.mlp[1].weight.data = torch.tensor(value).T\n","    if i == 2:\n","        notmiwae.encoder.mlp.mlp[1].bias.data= torch.tensor(value)\n","    if i == 3:\n","        notmiwae.encoder.mlp.mlp[3].weight.data = torch.tensor(value).T\n","    if i == 4:\n","        notmiwae.encoder.mlp.mlp[3].bias.data= torch.tensor(value)\n","    if i == 5:\n","        notmiwae.encoder.to_mu.weight.data= torch.tensor(value).T\n","    if i == 6:\n","        notmiwae.encoder.to_mu.bias.data= torch.tensor(value)\n","    \n","    if i == 7:\n","        notmiwae.encoder.to_logsigma2[0].weight.data= torch.tensor(value).T\n","    if i == 8:\n","        notmiwae.encoder.to_logsigma2[0].bias.data= torch.tensor(value)\n","\n","    if i == 9:\n","        notmiwae.decoder.to_mu.weight.data= torch.tensor(value).T\n","    if i == 10:\n","        notmiwae.decoder.to_mu.bias.data= torch.tensor(value)\n","    if i == 11:\n","        notmiwae.logits.w.data = torch.tensor(value)\n","    if i == 12:\n","        notmiwae.logits.b.data = torch.tensor(value)\n","    "]},{"cell_type":"code","execution_count":1789,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["encoder.mlp.mlp.1.weight torch.Size([128, 11])\n","encoder.mlp.mlp.1.bias torch.Size([128])\n","encoder.mlp.mlp.3.weight torch.Size([128, 128])\n","encoder.mlp.mlp.3.bias torch.Size([128])\n","encoder.to_mu.weight torch.Size([10, 128])\n","encoder.to_mu.bias torch.Size([10])\n","encoder.to_logsigma2.0.weight torch.Size([10, 128])\n","encoder.to_logsigma2.0.bias torch.Size([10])\n","decoder.logsigma2 torch.Size([])\n","decoder.to_mu.weight torch.Size([11, 10])\n","decoder.to_mu.bias torch.Size([11])\n","logits.w torch.Size([1, 1, 11])\n","logits.b torch.Size([1, 1, 11])\n"]}],"source":["for name,param in notmiwae.named_parameters():\n","    print(name,param.shape)"]},{"cell_type":"code","execution_count":1790,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["encoder.mlp.mlp.1.weight Parameter containing:\n","tensor([[ 0.0984, -0.0659,  0.0538,  ...,  0.0332,  0.2043, -0.0129],\n","        [ 0.0206, -0.0667,  0.0755,  ..., -0.1998, -0.0629,  0.1286],\n","        [-0.2027, -0.1345,  0.0490,  ...,  0.0627,  0.1903,  0.2052],\n","        ...,\n","        [ 0.1632,  0.0496, -0.1738,  ...,  0.1082,  0.0510, -0.0415],\n","        [-0.0343, -0.0813, -0.1049,  ..., -0.1233, -0.0508,  0.2010],\n","        [-0.0029, -0.0982,  0.2011,  ...,  0.0455, -0.0664, -0.1178]],\n","       requires_grad=True)\n","encoder.mlp.mlp.1.bias Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","encoder.mlp.mlp.3.weight Parameter containing:\n","tensor([[-0.0065, -0.0382, -0.1006,  ..., -0.0540, -0.0867, -0.0709],\n","        [-0.0106, -0.1505,  0.1273,  ..., -0.0493,  0.0723,  0.0854],\n","        [ 0.0534, -0.0736,  0.0079,  ...,  0.0383,  0.1310, -0.0940],\n","        ...,\n","        [-0.0569,  0.0119, -0.0660,  ...,  0.0969,  0.1096,  0.0405],\n","        [-0.0512,  0.1095, -0.1275,  ...,  0.0019, -0.0666, -0.0213],\n","        [ 0.0464, -0.0933, -0.0420,  ..., -0.0243, -0.1349,  0.0532]],\n","       requires_grad=True)\n","encoder.mlp.mlp.3.bias Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","encoder.to_mu.weight Parameter containing:\n","tensor([[-0.0419, -0.0350, -0.0160,  ...,  0.0910,  0.1892,  0.0780],\n","        [ 0.0468, -0.0965,  0.0331,  ...,  0.0630, -0.2001,  0.1211],\n","        [ 0.0508,  0.1651, -0.0994,  ..., -0.0987, -0.2040,  0.1943],\n","        ...,\n","        [ 0.1118, -0.0187, -0.0929,  ..., -0.0112,  0.1725,  0.0122],\n","        [ 0.1756,  0.0626,  0.1689,  ...,  0.1947,  0.0505,  0.0713],\n","        [ 0.1313,  0.0427, -0.1207,  ...,  0.1872,  0.0161, -0.1224]],\n","       requires_grad=True)\n","encoder.to_mu.bias Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","encoder.to_logsigma2.0.weight Parameter containing:\n","tensor([[-0.1128, -0.0130,  0.1280,  ...,  0.1828, -0.1224, -0.0524],\n","        [ 0.1432,  0.1876,  0.2062,  ..., -0.1213, -0.0417,  0.1267],\n","        [ 0.1737, -0.1234,  0.0184,  ...,  0.1792,  0.0612, -0.1092],\n","        ...,\n","        [-0.1340, -0.0683,  0.1284,  ..., -0.1195, -0.0233,  0.1913],\n","        [-0.1064,  0.0051, -0.0850,  ..., -0.0089, -0.1147, -0.2056],\n","        [-0.0192,  0.1888,  0.1642,  ...,  0.0031,  0.2014,  0.0726]],\n","       requires_grad=True)\n","encoder.to_logsigma2.0.bias Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","decoder.logsigma2 Parameter containing:\n","tensor(1.4881, requires_grad=True)\n","decoder.to_mu.weight Parameter containing:\n","tensor([[-0.0396,  0.4560,  0.4687, -0.0985,  0.1195, -0.4388, -0.2719, -0.4473,\n","          0.0855, -0.2501],\n","        [ 0.3542, -0.5011,  0.3752, -0.0146, -0.0619, -0.1438, -0.1847,  0.5063,\n","         -0.3896, -0.4401],\n","        [-0.2648,  0.0523,  0.2338,  0.0692,  0.0820, -0.2714, -0.1374,  0.0947,\n","          0.1001, -0.2990],\n","        [-0.0088, -0.4377, -0.1076,  0.5265, -0.4304, -0.4282, -0.4963, -0.0821,\n","         -0.3104, -0.1972],\n","        [-0.0954, -0.2092,  0.1945, -0.5059,  0.3228, -0.2241,  0.1708, -0.1664,\n","         -0.4111, -0.0717],\n","        [-0.2519, -0.3242,  0.4268, -0.3757,  0.2506, -0.3098, -0.0774,  0.1698,\n","          0.2102,  0.3106],\n","        [-0.0230,  0.1842,  0.3096, -0.0957, -0.5252, -0.1740, -0.3685, -0.5172,\n","         -0.3985, -0.2157],\n","        [ 0.1024,  0.1890,  0.0588,  0.3558, -0.0263,  0.1633, -0.2520,  0.4703,\n","         -0.1800,  0.3919],\n","        [ 0.3938,  0.3739, -0.0704,  0.1335, -0.3720,  0.1266, -0.3458, -0.0965,\n","          0.2974,  0.2100],\n","        [ 0.2824,  0.2543, -0.4178,  0.4381, -0.2877, -0.0449,  0.1602,  0.2805,\n","          0.4650, -0.4308],\n","        [ 0.4585, -0.1483, -0.5236, -0.1913,  0.4005,  0.0237,  0.3835, -0.3204,\n","          0.1355, -0.3440]], requires_grad=True)\n","decoder.to_mu.bias Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","logits.w Parameter containing:\n","tensor([[[ 0.2165,  0.0847, -0.5982, -0.2608,  0.0500,  0.1549, -0.5273,\n","          -0.4141,  0.6028, -0.6439, -0.4283]]], requires_grad=True)\n","logits.b Parameter containing:\n","tensor([[[ 0.6351, -0.3861, -0.4461,  0.1963, -0.6901,  0.1089, -0.2697,\n","           0.2098,  0.3418, -0.4062,  0.3143]]], requires_grad=True)\n"]}],"source":["for name,param in notmiwae.named_parameters():\n","    print(name,param)"]},{"cell_type":"code","execution_count":1791,"metadata":{},"outputs":[],"source":["# stop"]},{"cell_type":"code","execution_count":1792,"metadata":{},"outputs":[],"source":["batch_pointer = 0\n","\n","batch_size = 1\n","start = time.time()\n","best = float(\"inf\")\n","\n","\n","\n","x_batch = Xz[batch_pointer: batch_pointer + batch_size, :]\n","s_batch = S[batch_pointer: batch_pointer + batch_size, :]"]},{"cell_type":"code","execution_count":1793,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]]\n","[[ 0.         -0.47865728 -0.6131152   0.          0.         -0.19453143\n","   0.65043349  1.52899789 -1.04822629 -0.43681578 -1.06808001]]\n"]}],"source":["print(s_batch)\n","print(x_batch)"]},{"cell_type":"markdown","metadata":{},"source":["Run for Tensorflow"]},{"cell_type":"code","execution_count":1794,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["value: [[[ 0.1506573  -0.47865728 -0.6131152   1.9933782  -0.02659437\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]\n","  [-2.123363   -0.47865728 -0.6131152   1.8904002  -2.0768008\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]\n","  [-0.51670325 -0.47865728 -0.6131152   0.44300494  0.12989177\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]]]\n"]}],"source":["# Assume 'sess' is your TensorFlow session\n","value1 = sess.run(l_out_mixed, feed_dict={x_pl: x_batch, s_pl: s_batch, n_pl: n_samples})\n","\n","# 'your_input_data', 'your_mask_data', and 'your_sample_size' are the actual data and sample size you want to use\n","\n","# print(\"Logits values:\", value1)\n","print(\"value:\", value1)\n","\n","z_smp = sess.run([l_z], feed_dict={x_pl: x_batch, s_pl: s_batch, n_pl: n_samples})"]},{"cell_type":"code","execution_count":1795,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor 'Sum_2:0' shape=(None, 3) dtype=float32>"]},"execution_count":1795,"metadata":{},"output_type":"execute_result"}],"source":["lpz"]},{"cell_type":"code","execution_count":1796,"metadata":{},"outputs":[],"source":["# Assume 'sess' is your TensorFlow session\n","value1, z_smp, mu_t, log_prob_s_given_x_tf, log_prob_x_given_z_tf, log_prob_z_tf, log_prob_z_given_x_tf,loss_tf \\\n","      = sess.run([l_out_mixed,l_z,mu, lpsx, lpxz, lpz ,lqzx, notMIWAE], feed_dict={x_pl: x_batch, s_pl: s_batch, n_pl: n_samples})\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Run for Pytorch"]},{"cell_type":"code","execution_count":1797,"metadata":{},"outputs":[],"source":["# l_w = lpxz + lpsx + lpz - lqzx\n","lr = 0.01\n","optim = torch.optim.Adam(notmiwae.parameters(), lr=lr)\n","optim.zero_grad()"]},{"cell_type":"code","execution_count":1798,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 0.1507, -0.4787, -0.6131,  1.9934, -0.0266, -0.1945,  0.6504,\n","           1.5290, -1.0482, -0.4368, -1.0681],\n","         [-2.1234, -0.4787, -0.6131,  1.8904, -2.0768, -0.1945,  0.6504,\n","           1.5290, -1.0482, -0.4368, -1.0681],\n","         [-0.5167, -0.4787, -0.6131,  0.4430,  0.1299, -0.1945,  0.6504,\n","           1.5290, -1.0482, -0.4368, -1.0681]]], grad_fn=<AddBackward0>)\n","tensor([[[-0.1049, -0.0078,  0.0999, -0.4687,  0.0331, -0.0470, -0.4852,\n","          -0.5463, -0.8379,  0.0197,  0.5921],\n","         [-0.5972, -0.0078,  0.0999, -0.4418, -0.0693, -0.0470, -0.4852,\n","          -0.5463, -0.8379,  0.0197,  0.5921],\n","         [-0.2494, -0.0078,  0.0999, -0.0644,  0.0410, -0.0470, -0.4852,\n","          -0.5463, -0.8379,  0.0197,  0.5921]]], grad_fn=<MulBackward0>)\n"]}],"source":["\n","x__ = torch.FloatTensor(x_batch)\n","s__ = torch.FloatTensor(s_batch)\n","\n","n_samples = n_samples\n","z_mu, z_sigma = notmiwae.encoder(x__) # (batch, n_latent), (batch, n_latent)\n","\n","law_z_given_x = torch.distributions.normal.Normal(loc = z_mu, scale = z_sigma) # Distribution with parameter of size (batch, n_latent)\n","# law_z_given_x = GaussDistribution(loc = z_mu, scale = z_sigma)\n","\n","        \n","# Sampling and computing log_probs\n","# z_samples = law_z_given_x.rsample((n_samples,)) # (n_samples, batch, n_latent)\n","# z_samples = torch.tensor(z_smp).transpose(0,1)\n","z_samples = z_mu + EPS1_pytorch * z_sigma\n","log_prob_z_given_x = law_z_given_x.log_prob(z_samples).sum(dim=-1) # (n_samples, batch)\n","        \n","# Transposing\n","z_samples = z_samples.transpose(0,1) # (batch, n_samples, n_latent)\n","log_prob_z_given_x = log_prob_z_given_x.transpose(0,1) # (batch, n_samples)\n","\n","# Prior\n","log_prob_z = notmiwae.prior.log_prob(z_samples).sum(dim=-1) # (batch, n_samples)\n","\n","x_mu, x_sigma = notmiwae.decoder(z_samples) # (batch, n_samples, input_size), (batch, n_samples, input_size)\n","\n","\n","law_x_given_z = torch.distributions.normal.Normal(loc = x_mu, scale = x_sigma) # Distribution with parameter of size (batch, n_samples, input_size)\n","            # law_x_given_z = GaussDistribution(loc = x_mu, scale = x_sigma) # Distribution with parameter of size (batch, n_samples, input_size)\n","\n","        # Sampling and computing log_probs of the observed input\n","\n","x_samples  = law_x_given_z.rsample() # (batch, n_samples, input_size)\n","log_prob_x_given_z = (law_x_given_z.log_prob(x__.unsqueeze(1)) * s__.unsqueeze(1)).sum(dim=-1) # (batch, n_samples)\n","\n","        \n","        \n","        # Missing mechanism\n","        # We recreate the x_sample using the real x we know (x_o) and the x_samples we created from z (x_m).\n","# mixed_x_samples = x_samples * (1-s__).unsqueeze(1) + (x__*s__).unsqueeze(1) # (batch, n_samples, input_size)\n","mixed_x_samples = x_mu * (1-s__).unsqueeze(1) + (x__*s__).unsqueeze(1) # (batch, n_samples, input_size)\n","print(mixed_x_samples)\n","logits_pytorch = notmiwae.logits(mixed_x_samples) # (batch, n_samples, input_size)\n","print(logits_pytorch)        \n","law_s_given_x = BernoulliDistribution(logits=logits_pytorch) # Distribution with parameter of size (batch, n_samples, input_size)\n","        # law_s_given_x = torch.distributions.bernoulli.Bernoulli(logits=logits)\n","\n","\n","log_prob_s_given_x = law_s_given_x.log_prob(s__.unsqueeze(1)).sum(dim=-1) # (batch, n_samples)\n","\n","# if return_x_samples:\n","#     return log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x, x_samples # 4x(batch, n_samples), (batch, n_samples, input_size)\n","log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x # (batch, n_samples)\n","\n","# value2 = log_prob_s_given_x + log_prob_x_given_z + log_prob_z - log_prob_z_given_x\n","\n","loss_pytorch = notmiwae.loss(log_prob_s_given_x, log_prob_x_given_z, log_prob_z, log_prob_z_given_x)\n","\n","value2 = mixed_x_samples\n","value2 = value2.detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1799,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 0.1506573  -0.47865728 -0.6131152   1.9933782  -0.02659437\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]\n","  [-2.123363   -0.47865728 -0.6131152   1.8904002  -2.0768008\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]\n","  [-0.51670325 -0.47865728 -0.6131152   0.44300494  0.12989177\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]]]\n"]}],"source":["print(value1)"]},{"cell_type":"code","execution_count":1800,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[ 0.15065712 -0.47865728 -0.6131152   1.993378   -0.02659458\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]\n","  [-2.1233633  -0.47865728 -0.6131152   1.8904003  -2.0768008\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]\n","  [-0.51670337 -0.47865728 -0.6131152   0.44300503  0.12989146\n","   -0.19453143  0.6504335   1.5289979  -1.0482262  -0.43681577\n","   -1.0680801 ]]]\n"]}],"source":["print(value2)"]},{"cell_type":"code","execution_count":1801,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[[-1.7881393e-07  0.0000000e+00  0.0000000e+00 -1.1920929e-07\n","   -2.0489097e-07  0.0000000e+00  0.0000000e+00  0.0000000e+00\n","    0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","  [-2.3841858e-07  0.0000000e+00  0.0000000e+00  1.1920929e-07\n","    0.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n","    0.0000000e+00  0.0000000e+00  0.0000000e+00]\n","  [-1.1920929e-07  0.0000000e+00  0.0000000e+00  8.9406967e-08\n","   -3.1292439e-07  0.0000000e+00  0.0000000e+00  0.0000000e+00\n","    0.0000000e+00  0.0000000e+00  0.0000000e+00]]]\n"]}],"source":["print((value2 - value1))"]},{"cell_type":"code","execution_count":1802,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-9.648502e-07\n"]}],"source":["print((value2 - value1).sum())"]},{"cell_type":"code","execution_count":1803,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 3, 11)\n"]}],"source":["print(mu_t.shape)"]},{"cell_type":"code","execution_count":1804,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 3, 11)\n"]}],"source":["print(x_mu.detach().numpy().shape)"]},{"cell_type":"code","execution_count":1805,"metadata":{},"outputs":[{"data":{"text/plain":["array([[[-1.7881393e-07, -1.7881393e-07, -1.7881393e-07, -1.1920929e-07,\n","         -2.0489097e-07, -2.6822090e-07, -2.0861626e-07,  8.9406967e-08,\n","          2.9802322e-07,  2.9802322e-07,  2.0861626e-07],\n","        [-2.3841858e-07, -5.9604645e-08, -2.0861626e-07,  1.1920929e-07,\n","          0.0000000e+00, -1.1920929e-07, -1.3411045e-07,  1.1920929e-07,\n","          3.5762787e-07,  3.5762787e-07,  0.0000000e+00],\n","        [-1.1920929e-07, -8.9406967e-08, -1.0430813e-07,  8.9406967e-08,\n","         -3.1292439e-07, -1.1920929e-07,  5.9604645e-08,  1.7881393e-07,\n","          2.9802322e-07,  2.3841858e-07, -1.6391277e-07]]], dtype=float32)"]},"execution_count":1805,"metadata":{},"output_type":"execute_result"}],"source":["x_mu.detach().numpy() - mu_t"]},{"cell_type":"code","execution_count":1806,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["5.7183206e-06\n"]}],"source":["print(np.abs(x_mu.detach().numpy() - mu_t).sum())"]},{"cell_type":"code","execution_count":1807,"metadata":{},"outputs":[],"source":["_, _loss, _step, log_prob_s_given_x_tf, log_prob_x_given_z_tf, log_prob_z_tf, log_prob_z_given_x_tf\\\n","      = sess.run([train_op, loss, global_step, lpsx, lpxz, lpz ,lqzx], {x_pl: x_batch, s_pl: s_batch, n_pl: n_samples})\n"]},{"cell_type":"code","execution_count":1808,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["29.048903\n"]}],"source":["print(_loss)"]},{"cell_type":"code","execution_count":1809,"metadata":{},"outputs":[],"source":["loss_pytorch.backward()\n","optim.step()"]},{"cell_type":"code","execution_count":1815,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["encoder.mlp.mlp.1.weight Parameter containing:\n","tensor([[ 0.0984, -0.0759,  0.0438,  ...,  0.0232,  0.1943, -0.0229],\n","        [ 0.0206, -0.0567,  0.0855,  ..., -0.1898, -0.0529,  0.1386],\n","        [-0.2027, -0.1245,  0.0590,  ...,  0.0727,  0.2003,  0.2152],\n","        ...,\n","        [ 0.1632,  0.0396, -0.1838,  ...,  0.0982,  0.0410, -0.0515],\n","        [-0.0343, -0.0913, -0.1149,  ..., -0.1333, -0.0608,  0.1910],\n","        [-0.0029, -0.1082,  0.1911,  ...,  0.0355, -0.0764, -0.1278]],\n","       requires_grad=True)\n","encoder.mlp.mlp.1.bias Parameter containing:\n","tensor([ 0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n","        -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,  0.0100,  0.0100, -0.0100,\n","        -0.0100,  0.0100, -0.0100, -0.0100,  0.0100, -0.0100, -0.0100,  0.0100,\n","        -0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,\n","         0.0100,  0.0100,  0.0100, -0.0100,  0.0100,  0.0100, -0.0100,  0.0100,\n","         0.0100,  0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n","        -0.0100, -0.0100,  0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100,\n","        -0.0100,  0.0100, -0.0100,  0.0100,  0.0100,  0.0100,  0.0100,  0.0100,\n","         0.0100,  0.0100,  0.0100,  0.0100, -0.0100, -0.0100,  0.0100,  0.0100,\n","         0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100, -0.0100,  0.0100,\n","        -0.0100,  0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100,  0.0100,\n","         0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n","         0.0100,  0.0100,  0.0100,  0.0100, -0.0100,  0.0100,  0.0100,  0.0100,\n","         0.0100,  0.0100, -0.0100,  0.0100, -0.0100, -0.0100,  0.0100,  0.0100,\n","        -0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100, -0.0100,  0.0100,\n","        -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100],\n","       requires_grad=True)\n","encoder.mlp.mlp.3.weight Parameter containing:\n","tensor([[ 0.0035, -0.0482, -0.1106,  ..., -0.0440, -0.0767, -0.0609],\n","        [-0.0206, -0.1405,  0.1373,  ..., -0.0593,  0.0623,  0.0754],\n","        [ 0.0434, -0.0636,  0.0179,  ...,  0.0283,  0.1210, -0.1040],\n","        ...,\n","        [-0.0469,  0.0019, -0.0760,  ...,  0.1069,  0.1196,  0.0505],\n","        [-0.0412,  0.0995, -0.1375,  ...,  0.0119, -0.0566, -0.0113],\n","        [ 0.0364, -0.0833, -0.0320,  ..., -0.0343, -0.1449,  0.0432]],\n","       requires_grad=True)\n","encoder.mlp.mlp.3.bias Parameter containing:\n","tensor([-0.0100,  0.0100,  0.0100,  0.0100, -0.0100,  0.0100, -0.0100, -0.0100,\n","         0.0100, -0.0100, -0.0100, -0.0100, -0.0100,  0.0100, -0.0100, -0.0100,\n","        -0.0100, -0.0100,  0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100,\n","         0.0100, -0.0100, -0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100,\n","        -0.0100,  0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n","        -0.0100, -0.0100,  0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100,\n","        -0.0100,  0.0100,  0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100,\n","        -0.0100, -0.0100, -0.0100,  0.0100,  0.0100, -0.0100,  0.0100, -0.0100,\n","         0.0100, -0.0100,  0.0100,  0.0100, -0.0100,  0.0100,  0.0100, -0.0100,\n","        -0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100,  0.0100,  0.0100,\n","        -0.0100, -0.0100, -0.0100, -0.0100, -0.0100, -0.0100,  0.0100, -0.0100,\n","        -0.0100,  0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100, -0.0100,\n","         0.0100, -0.0100, -0.0100,  0.0100,  0.0100,  0.0100, -0.0100, -0.0100,\n","         0.0100, -0.0100,  0.0100,  0.0100, -0.0100,  0.0100, -0.0100,  0.0100,\n","         0.0100,  0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100,  0.0100,\n","        -0.0100,  0.0100,  0.0100, -0.0100, -0.0100, -0.0100, -0.0100,  0.0100],\n","       requires_grad=True)\n","encoder.to_mu.weight Parameter containing:\n","tensor([[-0.0519, -0.0250, -0.0060,  ...,  0.1010,  0.1792,  0.0680],\n","        [ 0.0368, -0.0865,  0.0431,  ...,  0.0730, -0.2101,  0.1111],\n","        [ 0.0408,  0.1751, -0.0894,  ..., -0.0887, -0.2140,  0.1843],\n","        ...,\n","        [ 0.1218, -0.0287, -0.1029,  ..., -0.0212,  0.1825,  0.0222],\n","        [ 0.1656,  0.0726,  0.1789,  ...,  0.2047,  0.0405,  0.0613],\n","        [ 0.1213,  0.0527, -0.1107,  ...,  0.1972,  0.0061, -0.1324]],\n","       requires_grad=True)\n","encoder.to_mu.bias Parameter containing:\n","tensor([ 0.0100,  0.0100,  0.0100, -0.0100,  0.0100,  0.0100,  0.0100, -0.0100,\n","         0.0100,  0.0100], requires_grad=True)\n","encoder.to_logsigma2.0.weight Parameter containing:\n","tensor([[-0.1228, -0.0030,  0.1380,  ...,  0.1928, -0.1324, -0.0624],\n","        [ 0.1332,  0.1976,  0.2162,  ..., -0.1113, -0.0517,  0.1167],\n","        [ 0.1837, -0.1334,  0.0084,  ...,  0.1692,  0.0712, -0.0992],\n","        ...,\n","        [-0.1440, -0.0583,  0.1384,  ..., -0.1095, -0.0333,  0.1813],\n","        [-0.1164,  0.0151, -0.0750,  ...,  0.0011, -0.1247, -0.2156],\n","        [-0.0292,  0.1988,  0.1742,  ...,  0.0131,  0.1914,  0.0626]],\n","       requires_grad=True)\n","encoder.to_logsigma2.0.bias Parameter containing:\n","tensor([ 0.0100,  0.0100, -0.0100,  0.0100, -0.0100, -0.0100, -0.0100,  0.0100,\n","         0.0100,  0.0100], requires_grad=True)\n","decoder.logsigma2 Parameter containing:\n","tensor(1.4781, requires_grad=True)\n","decoder.to_mu.weight Parameter containing:\n","tensor([[-0.0296,  0.4660,  0.4787, -0.1085,  0.1295, -0.4288, -0.2619, -0.4573,\n","          0.0955, -0.2401],\n","        [ 0.3642, -0.4911,  0.3852, -0.0246, -0.0519, -0.1338, -0.1747,  0.4963,\n","         -0.3796, -0.4301],\n","        [-0.2548,  0.0623,  0.2438,  0.0592,  0.0720, -0.2614, -0.1274,  0.1047,\n","          0.1101, -0.2890],\n","        [-0.0188, -0.4477, -0.1176,  0.5365, -0.4404, -0.4382, -0.5063, -0.0721,\n","         -0.3204, -0.2072],\n","        [-0.0854, -0.1992,  0.2045, -0.5159,  0.3328, -0.2141,  0.1808, -0.1764,\n","         -0.4011, -0.0617],\n","        [-0.2619, -0.3342,  0.4168, -0.3657,  0.2406, -0.3198, -0.0874,  0.1798,\n","          0.2002,  0.3006],\n","        [-0.0330,  0.1742,  0.2996, -0.0857, -0.5152, -0.1840, -0.3785, -0.5072,\n","         -0.4085, -0.2257],\n","        [ 0.0924,  0.1790,  0.0488,  0.3658, -0.0363,  0.1533, -0.2420,  0.4603,\n","         -0.1900,  0.3819],\n","        [ 0.4038,  0.3839, -0.0604,  0.1235, -0.3620,  0.1366, -0.3358, -0.1065,\n","          0.3074,  0.2200],\n","        [ 0.2924,  0.2643, -0.4078,  0.4281, -0.2777, -0.0349,  0.1702,  0.2705,\n","          0.4750, -0.4208],\n","        [ 0.4685, -0.1383, -0.5136, -0.2013,  0.3905,  0.0337,  0.3935, -0.3104,\n","          0.1455, -0.3340]], requires_grad=True)\n","decoder.to_mu.bias Parameter containing:\n","tensor([-0.0100, -0.0100, -0.0100,  0.0100, -0.0100,  0.0100,  0.0100,  0.0100,\n","        -0.0100, -0.0100, -0.0100], requires_grad=True)\n","logits.w Parameter containing:\n","tensor([[[ 0.2265,  0.0747, -0.6082, -0.2708,  0.0400,  0.1449, -0.5173,\n","          -0.4041,  0.5928, -0.6539, -0.4383]]], requires_grad=True)\n","logits.b Parameter containing:\n","tensor([[[ 0.6451, -0.3961, -0.4361,  0.1863, -0.6801,  0.0989, -0.2597,\n","           0.2198,  0.3318, -0.3962,  0.3243]]], requires_grad=True)\n"]}],"source":["for name,param in notmiwae.named_parameters():\n","    print(name,param)"]},{"cell_type":"markdown","metadata":{},"source":["[[[-0.11418875  0.11287624  0.6023344  -0.00497036  0.61081624\n","    0.28656006 -0.45228887 -0.00628437 -0.5553096   0.19696355\n","    0.57544184]]]"]},{"cell_type":"code","execution_count":1811,"metadata":{},"outputs":[],"source":["# Get the list of trainable variables\n","trainable_variables = tf.compat.v1.trainable_variables()\n","\n","# Print the names and shapes of the variables\n","# for var in trainable_variables:\n","#     print(f\"Variable Name: {var.name}, Shape: {var.shape}, Value: {var}\")\n","\n","# Get the values of the variables\n","variable_values = sess.run(trainable_variables)\n","\n","# Access a specific variable's value (e.g., the first variable)\n","first_variable_value = variable_values[1]\n","# print(f\"Value of the first variable: {first_variable_value}\")\n","\n","named_variables = zip([var.name for var in trainable_variables],variable_values )"]},{"cell_type":"code","execution_count":1812,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 data_process/logstd:0 1.4870913\n","1 l_enc1/kernel:0 [[ 0.0983675   0.02060916 -0.20272103 ...  0.16320227 -0.03432383\n","  -0.00287151]\n"," [-0.06688102 -0.06574945 -0.13345833 ...  0.04859415 -0.08232237\n","  -0.09917849]\n"," [ 0.05280048  0.07654744  0.05004921 ... -0.17482089 -0.10587645\n","   0.20012388]\n"," ...\n"," [ 0.03219371 -0.19880384  0.06365755 ...  0.10718352 -0.12430713\n","   0.04450387]\n"," [ 0.20325452 -0.06193014  0.1912942  ...  0.04995964 -0.05176842\n","  -0.06735089]\n"," [-0.0139094   0.12963411  0.20617121 ... -0.04253913  0.19995299\n","  -0.11877555]]\n","2 l_enc1/bias:0 [ 0.001      -0.001      -0.001      -0.001      -0.001      -0.00099965\n"," -0.001      -0.001      -0.001      -0.00099999 -0.001      -0.001\n"," -0.001       0.001       0.00099999 -0.001      -0.001       0.001\n"," -0.001      -0.001       0.001      -0.001      -0.001       0.001\n"," -0.001      -0.001      -0.00099999  0.001       0.001       0.001\n","  0.001       0.001       0.001       0.001       0.001      -0.001\n","  0.001       0.001      -0.001       0.001       0.001       0.001\n"," -0.001       0.001      -0.001      -0.001      -0.001      -0.001\n"," -0.001      -0.001       0.001       0.001       0.001      -0.001\n"," -0.001      -0.00099999 -0.00099995  0.001      -0.001       0.001\n","  0.001       0.001       0.00099999  0.001       0.001       0.001\n","  0.001       0.001      -0.001      -0.001       0.001       0.001\n","  0.001      -0.001       0.001      -0.00099998 -0.001      -0.001\n"," -0.001       0.001      -0.001       0.001      -0.001       0.001\n"," -0.00099991 -0.001      -0.001       0.001       0.001      -0.001\n"," -0.001      -0.001      -0.001      -0.001      -0.001      -0.001\n","  0.001       0.00099999  0.001       0.001      -0.001       0.001\n","  0.001       0.001       0.001       0.00099999 -0.001       0.001\n"," -0.001      -0.001       0.001       0.001      -0.001      -0.00099998\n"," -0.00099999  0.001       0.001       0.001      -0.00099999  0.001\n"," -0.001      -0.001      -0.00099999 -0.001      -0.001       0.001\n","  0.001       0.001     ]\n","3 l_enc2/kernel:0 [[-0.00554405 -0.01162818  0.05240939 ... -0.05588333 -0.05018652\n","   0.04540038]\n"," [-0.03922934 -0.14946984 -0.07261024 ...  0.01091149  0.10848981\n","  -0.09234147]\n"," [-0.10159547  0.12830412  0.00886148 ... -0.06699681 -0.12854755\n","  -0.0409608 ]\n"," ...\n"," [-0.05301273 -0.05027157  0.0372806  ...  0.09788559  0.00291066\n","  -0.02534216]\n"," [-0.085734    0.07129469  0.12995106 ...  0.11061175 -0.06558026\n","  -0.13585487]\n"," [-0.06987873  0.08436823 -0.09497727 ...  0.04153663 -0.02025546\n","   0.0521856 ]]\n","4 l_enc2/bias:0 [-0.001       0.001       0.001       0.001      -0.001       0.001\n"," -0.001      -0.001       0.001      -0.001      -0.001      -0.00099998\n"," -0.001       0.001      -0.001      -0.001      -0.001      -0.001\n","  0.001       0.001       0.001      -0.001      -0.001      -0.001\n","  0.00099999 -0.001      -0.001      -0.001       0.001      -0.001\n"," -0.001      -0.001      -0.001       0.001      -0.001       0.001\n"," -0.001      -0.001      -0.00099999 -0.001      -0.001      -0.001\n","  0.00099999 -0.001       0.001      -0.001      -0.001      -0.001\n"," -0.001       0.001       0.001      -0.001      -0.001       0.001\n","  0.001       0.001      -0.001      -0.00099998 -0.001       0.001\n","  0.001      -0.001       0.001      -0.001       0.001      -0.001\n","  0.001       0.001      -0.00099993  0.001       0.001      -0.001\n"," -0.001       0.001       0.001      -0.001      -0.001      -0.001\n","  0.00099999  0.001      -0.00099999 -0.00099999 -0.001      -0.001\n"," -0.001      -0.001       0.001      -0.001      -0.001       0.001\n","  0.001       0.001      -0.001      -0.00099999 -0.001      -0.001\n","  0.001      -0.001      -0.001       0.001       0.001       0.001\n"," -0.001      -0.00099998  0.001      -0.001       0.001       0.001\n"," -0.001       0.001      -0.001       0.00099998  0.001       0.001\n","  0.001       0.001      -0.001      -0.001      -0.001       0.001\n"," -0.001       0.001       0.001      -0.001      -0.001      -0.001\n"," -0.001       0.001     ]\n","5 q_mu/kernel:0 [[-0.04286809  0.04578643  0.04979229 ...  0.11281425  0.17460711\n","   0.1303134 ]\n"," [-0.03397851 -0.09546086  0.16606909 ... -0.0197484   0.0635636\n","   0.04366424]\n"," [-0.01498345  0.03412191 -0.09842011 ... -0.09388667  0.16988832\n","  -0.11972313]\n"," ...\n"," [ 0.09198379  0.06404836 -0.09769787 ... -0.01215751  0.19566996\n","   0.18816316]\n"," [ 0.18821332 -0.20114738 -0.20503983 ...  0.17348418  0.04949267\n","   0.01510799]\n"," [ 0.07704461  0.1200624   0.19330633 ...  0.01321344  0.07033361\n","  -0.1233758 ]]\n","6 q_mu/bias:0 [ 0.001  0.001  0.001 -0.001  0.001  0.001  0.001 -0.001  0.001  0.001]\n","7 q_logstd/kernel:0 [[-0.11381336  0.14224377  0.1746718  ... -0.13501891 -0.1074277\n","  -0.02016359]\n"," [-0.01201612  0.18862167 -0.12436736 ... -0.06732667  0.00607372\n","   0.18976465]\n"," [ 0.12898053  0.2071976   0.01738283 ...  0.12937167 -0.08396112\n","   0.16515473]\n"," ...\n"," [ 0.18382049 -0.12029355  0.17816323 ... -0.11849009 -0.0078992\n","   0.00406832]\n"," [-0.12337664 -0.04268773  0.06223148 ... -0.02432393 -0.11573158\n","   0.2004047 ]\n"," [-0.0534021   0.12572679 -0.10823534 ...  0.1903243  -0.20662549\n","   0.07155583]]\n","8 q_logstd/bias:0 [ 0.001  0.001 -0.001  0.001 -0.001 -0.001 -0.001  0.001  0.001  0.001]\n","9 mu/kernel:0 [[-0.03862991  0.35521156 -0.2637703  -0.00982333 -0.09442422 -0.25293884\n","  -0.02399248  0.10142171  0.39477074  0.28338313  0.45952612]\n"," [ 0.45696646 -0.5001025   0.0533024  -0.43870813 -0.208222   -0.32519782\n","   0.18316105  0.18796855  0.37487072  0.25534236 -0.14728321]\n"," [ 0.46970868  0.37624872  0.23477282 -0.10863832  0.1954937   0.4258253\n","   0.30862296  0.0577703  -0.06942888 -0.41683897 -0.5225778 ]\n"," [-0.09953169 -0.01555778  0.0682475   0.52752817 -0.5068543  -0.3747322\n","  -0.09465299  0.3568415   0.13246818  0.43705708 -0.19225964]\n"," [ 0.1204669  -0.06085026  0.0810307  -0.43140137  0.3237754   0.24963313\n","  -0.5241664  -0.02726567 -0.37104797 -0.2867015   0.39951354]\n"," [-0.43776476 -0.14282127 -0.27041107 -0.4291923  -0.22306812 -0.31084582\n","  -0.17497343  0.16229866  0.12755775 -0.04390325  0.02472783]\n"," [-0.2709299  -0.18371432 -0.13639    -0.49728394  0.171786   -0.07839364\n","  -0.36948383 -0.25102305 -0.34477785  0.1611588   0.3845011 ]\n"," [-0.44826102  0.50531733  0.09565587 -0.08106149 -0.16743438  0.17077436\n","  -0.5161665   0.46932155 -0.09753686  0.27947694 -0.31935978]\n"," [ 0.08648258 -0.388629    0.10105317 -0.3114025  -0.41013172  0.20917296\n","  -0.39952344 -0.18097648  0.29839784  0.46600837  0.13654423]\n"," [-0.24912627 -0.43913054 -0.29796463 -0.19815429 -0.07073668  0.3096076\n","  -0.21670748  0.39087677  0.21100837 -0.4297684  -0.34300542]]\n","10 mu/bias:0 [-0.001      -0.00099999 -0.00099999  0.001      -0.00099999  0.00099998\n","  0.00099998  0.001      -0.00099999 -0.00099999 -0.00099999]\n","11 W:0 [[[ 0.21750213  0.08370268 -0.5992227  -0.26180503  0.04895293\n","    0.15388797 -0.526308   -0.41309953  0.6017549  -0.64487517\n","   -0.42927787]]]\n","12 b:0 [[[ 0.6360589  -0.3870865  -0.44513014  0.19525866 -0.68911016\n","    0.10794067 -0.26872197  0.21077885  0.34081638 -0.40518993\n","    0.31532025]]]\n"]}],"source":["for i, (name, value) in enumerate(named_variables):\n","    print(i, (name),value)"]},{"cell_type":"code","execution_count":1813,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'stop' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1813], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n","\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"]}],"source":["stop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.distributions import Distribution\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.impute import SimpleImputer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from matplotlib.animation import FuncAnimation\n","from IPython.display import HTML\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import Any ,List"]},{"cell_type":"markdown","metadata":{},"source":["General case:\n","- Choose a prior for $Z$: $p(Z)$.\n","- Choose an observation model: $p_\\theta(X|Z)$\n","- Choose a variational posterior: $q_{\\gamma}(\\mathbf{z} | \\mathbf{x})$\n","\n","- Choose a missing model: $p_{\\phi}(\\mathbf{S} | \\mathbf{X^o, X^m})$\n","\n","\n","The ELBO in the MNAR case is\n","\n","$$ E_{(\\mathbf{z}_1, \\mathbf{x}_1^m)...(\\mathbf{z}_K, \\mathbf{x}_K^m)} \\left[ \\log \\frac{1}{K} \\sum_{k=1}^K \\frac{p_{\\phi}(\\mathbf{s} | \\mathbf{x}^o, \\mathbf{x}_k^m) p_{\\theta}(\\mathbf{x}^o | \\mathbf{z}_k) p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z} | \\mathbf{x}^o)} \\right]$$"]},{"cell_type":"markdown","metadata":{},"source":["### Classic case\n","The model we are building has a Gaussian prior and a Gaussian observation model (also the decoder ($z \\rightarrow x$) ),\n","\n","$$ p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{z} | \\mathbf{0}, \\mathbf{I})$$\n","\n","$$ p_\\theta(\\mathbf{x} | \\mathbf{z}) = \\mathcal{N}(\\mathbf{x} | \\mathbf{\\mu}_{\\theta}(\\mathbf{z}), \\sigma^2\\mathbf{I})$$\n","\n","$$ p_\\theta(\\mathbf{x}) = \\int p_\\theta(\\mathbf{x} | \\mathbf{z})p(\\mathbf{z}) d\\mathbf{z}$$\n","\n","where $\\mathbf{\\mu}_{\\theta}(\\mathbf{z}): \\mathbb{R}^d \\rightarrow \\mathbb{R}^p $ in general is a deep neural net, but in this case is a linear mapping, $\\mathbf{\\mu} = \\mathbf{Wz + b}$.\n","\n","The variational posterior (also the encoder ($x \\rightarrow z$) ) is also Gaussian\n","\n","$$q_{\\gamma}(\\mathbf{z} | \\mathbf{x}) = \\mathcal{N}(\\mathbf{z} | \\mu_{\\gamma}(\\mathbf{x}), \\sigma_{\\gamma}(\\mathbf{x})^2 \\mathbf{I})$$\n","\n","If the missing process is *missing at random*, it is ignorable and the ELBO becomes, as described in [the MIWAE paper](https://arxiv.org/abs/1812.02633)\n","\n","$$ E_{\\mathbf{z}_1...\\mathbf{z}_K} \\left[ \\log \\frac{1}{K}\\sum_{k=1}^K \\frac{p_{\\theta}(\\mathbf{x^o} | \\mathbf{z}_k)p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z}_k | \\mathbf{x^o})} \\right] $$\n","\n","When the missing process is MNAR it is non-ignorable and we need to include the missing model. In this example we include the missing model as a logistic regression in each feature dimension\n","\n","$$ p_{\\phi}(\\mathbf{s} | \\mathbf{x^o, x^m}) = \\text{Bern}(\\mathbf{s} | \\pi_{\\phi}(\\mathbf{x^o, x^m}))$$\n","\n","$$ \\pi_{\\phi, j}(x_j) = \\frac{1}{1 + e^{-\\text{logits}_j}} $$\n","\n","$$ \\text{logits}_j = W_j (x_j - b_j) $$\n","\n","The ELBO in the MNAR case becomes\n","\n","$$ E_{(\\mathbf{z}_1, \\mathbf{x}_1^m)...(\\mathbf{z}_K, \\mathbf{x}_K^m)} \\left[ \\log \\frac{1}{K} \\sum_{k=1}^K \\frac{p_{\\phi}(\\mathbf{s} | \\mathbf{x}^o, \\mathbf{x}_k^m) p_{\\theta}(\\mathbf{x}^o | \\mathbf{z}_k) p(\\mathbf{z}_k)}{q_{\\gamma}(\\mathbf{z} | \\mathbf{x}^o)} \\right]$$\n","\n","with $ z \\sim q_{\\gamma}(z|x^o), x^m\\sim p_\\theta(x^m|z)$"]},{"cell_type":"markdown","metadata":{},"source":["### Constant to define\n","\n"," - $K$ = $n_{\\text{samples}}$ the number of sample to estimate the expectation\n"," - $n_{\\text{latent}}$ the dimension of the latent space where $z$ lives\n"]},{"cell_type":"markdown","metadata":{},"source":["## Imputation\n","\n"," - RMSE imputation (easy to implement)\n","$$\n","\\hat{x}^m = \\mathbb{E}[x^m|x^o,s] \\approx \\sum_{k=1}^K \\alpha_k \\mathbb{E}[x^m|x^o,s]  ~~\\text{with} ~~ \\alpha _ k =\\frac{w_k}{w_1 + ... + w_K}\n","$$\n"," - Absolute value imputation (harder) 5NOT IMPLEMENTED\n","$$\n","F_j(x_j)= \\mathbb{E}[\\mathbb{1}_{x_j^m \\leq x_j}|x^o,s] \\approx \\sum_{k=1}^K \\alpha_k F_{x_j|x^o,s}(x_j) ~~\\text{with} ~~ \\alpha_k =\\frac{w_k}{w_1 + ... + w_K}\n","$$"]},{"cell_type":"markdown","metadata":{},"source":["### Load data\n","Here we use the white-wine dataset from the UCI database"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n","data = np.array(pd.read_csv(url, low_memory=False, sep=';'))\n","# ---- drop the classification attribute\n","data = data[:, :-1]"]},{"cell_type":"markdown","metadata":{},"source":["### Settings"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["N, D = data.shape\n","n_latent = D - 1\n","n_hidden = 128\n","n_samples = 20\n","max_iter = 30000\n","batch_size = 16"]},{"cell_type":"markdown","metadata":{},"source":["### Standardize data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ---- standardize data\n","data = data - np.mean(data, axis=0)\n","data = data / np.std(data, axis=0)\n","\n","# ---- random permutation\n","p = np.random.permutation(N)\n","data = data[p, :]\n","\n","# ---- we use the full dataset for training here, but you can make a train-val split\n","Xtrain = data.copy()\n","Xval = Xtrain.copy()"]},{"cell_type":"markdown","metadata":{},"source":["### Introduce missing \n","Here we denote\n","- Xnan: data matrix with np.nan as the missing entries\n","- Xz: data matrix with 0 as the missing entries\n","- S: missing mask \n","\n","The missing process depends on the missing data itself:\n","- in half the features, set the feature value to missing when it is higher than the feature mean"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def transform(data: np.array, d1, d2, threshold, prob, sign: int = 1) -> np.array:\n","    \"\"\"\n","    Introduce missing data.\n","    Mechanism: sign * x[i, d2] > threshold => x[i, d1] missing with probability prob.\n","    \n","    Args:\n","    - data (np.array): Input data array.\n","    - d1 (int): Index of the column where missing data will be introduced.\n","    - d2 (int): Index of the column used for the threshold comparison.\n","    - threshold (float): Threshold value for the comparison.\n","    - prob (float): Probability of introducing missing data.\n","    - sign (int, optional): Sign of the comparison (1 or -1). Default is 1.\n","\n","    Returns:\n","    - np.array: Transformed data with missing values introduced based on the specified mechanism.\n","    \"\"\"\n","    transformed_data = np.copy(data)\n","\n","    # Apply the transformation based on the specified mechanism\n","    mask = sign * data[:, d2] > threshold\n","    missing_values = np.random.choice([True, False], size=len(mask), p=[prob, 1 - prob])\n","    transformed_data[mask & missing_values, d1] = np.nan\n","\n","    return transformed_data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["581 / 53878\n"]}],"source":["test = transform(data,1,1,0.5,0.5)\n","print(f'{np.isnan(test).sum()} / {test.shape[0]*test.shape[1]}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ---- introduce missing process\n","Xnan = Xtrain.copy()\n","Xz = Xtrain.copy()\n","\n","mean = np.mean(Xnan[:, :int(D / 2)], axis=0)\n","ix_larger_than_mean = Xnan[:, :int(D / 2)] > mean\n","\n","Xnan[:, :int(D / 2)][ix_larger_than_mean] = np.nan\n","Xz[:, :int(D / 2)][ix_larger_than_mean] = 0\n","\n","S = np.array(~np.isnan(Xnan), dtype=np.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# stop"]},{"cell_type":"markdown","metadata":{},"source":["### Do the training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["__Xz = Xz\n","__S = S\n","__X = Xtrain"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0/30000 updates, 0.16 s, 38.91 train_loss, 34.10 val_loss\n","100/30000 updates, 0.11 s, -2.01 train_loss, -1.89 val_loss\n","200/30000 updates, 0.06 s, -12.98 train_loss, -13.06 val_loss\n","300/30000 updates, 0.06 s, -16.07 train_loss, -18.47 val_loss\n","400/30000 updates, 0.06 s, -22.65 train_loss, -22.25 val_loss\n","500/30000 updates, 0.06 s, -25.07 train_loss, -24.38 val_loss\n","600/30000 updates, 0.07 s, -25.60 train_loss, -26.55 val_loss\n","700/30000 updates, 0.06 s, -28.83 train_loss, -28.89 val_loss\n","800/30000 updates, 0.06 s, -29.53 train_loss, -30.18 val_loss\n","900/30000 updates, 0.06 s, -30.28 train_loss, -28.78 val_loss\n","1000/30000 updates, 0.06 s, -31.55 train_loss, -31.94 val_loss\n","1100/30000 updates, 0.06 s, -33.05 train_loss, -32.67 val_loss\n","1200/30000 updates, 0.06 s, -31.48 train_loss, -32.41 val_loss\n","1300/30000 updates, 0.06 s, -34.56 train_loss, -33.48 val_loss\n","1400/30000 updates, 0.06 s, -36.21 train_loss, -35.63 val_loss\n","1500/30000 updates, 0.06 s, -32.09 train_loss, -34.31 val_loss\n","1600/30000 updates, 0.06 s, -37.12 train_loss, -37.10 val_loss\n","1700/30000 updates, 0.06 s, -36.11 train_loss, -35.72 val_loss\n","1800/30000 updates, 0.06 s, -35.84 train_loss, -37.51 val_loss\n","1900/30000 updates, 0.06 s, -35.93 train_loss, -38.03 val_loss\n","2000/30000 updates, 0.06 s, -35.09 train_loss, -35.76 val_loss\n","2100/30000 updates, 0.06 s, -36.67 train_loss, -35.40 val_loss\n","2200/30000 updates, 0.06 s, -39.75 train_loss, -39.60 val_loss\n","2300/30000 updates, 0.06 s, -37.58 train_loss, -30.04 val_loss\n","2400/30000 updates, 0.06 s, -40.35 train_loss, -40.12 val_loss\n","2500/30000 updates, 0.06 s, -38.42 train_loss, -39.17 val_loss\n","2600/30000 updates, 0.06 s, -39.60 train_loss, -39.16 val_loss\n","2700/30000 updates, 0.06 s, -36.68 train_loss, -37.97 val_loss\n","2800/30000 updates, 0.06 s, -42.32 train_loss, -41.72 val_loss\n","2900/30000 updates, 0.06 s, -38.51 train_loss, -38.83 val_loss\n","3000/30000 updates, 0.06 s, -42.75 train_loss, -40.34 val_loss\n","3100/30000 updates, 0.06 s, -37.24 train_loss, -38.69 val_loss\n","3200/30000 updates, 0.06 s, -41.81 train_loss, -41.73 val_loss\n","3300/30000 updates, 0.06 s, -41.19 train_loss, -38.30 val_loss\n","3400/30000 updates, 0.06 s, -42.31 train_loss, -41.34 val_loss\n","3500/30000 updates, 0.06 s, -40.73 train_loss, -37.79 val_loss\n","3600/30000 updates, 0.06 s, -42.62 train_loss, -42.92 val_loss\n","3700/30000 updates, 0.06 s, -38.24 train_loss, -37.03 val_loss\n","3800/30000 updates, 0.06 s, -39.45 train_loss, -43.29 val_loss\n","3900/30000 updates, 0.06 s, -38.40 train_loss, -22.14 val_loss\n","4000/30000 updates, 0.06 s, -43.16 train_loss, -42.75 val_loss\n","4100/30000 updates, 0.06 s, -44.78 train_loss, -43.79 val_loss\n","4200/30000 updates, 0.06 s, -36.14 train_loss, -39.10 val_loss\n","4300/30000 updates, 0.06 s, -44.28 train_loss, -43.44 val_loss\n","4400/30000 updates, 0.06 s, -42.00 train_loss, -43.35 val_loss\n","4500/30000 updates, 0.06 s, -44.46 train_loss, -42.43 val_loss\n","4600/30000 updates, 0.06 s, -41.27 train_loss, -42.40 val_loss\n","4700/30000 updates, 0.06 s, -42.84 train_loss, -41.32 val_loss\n","4800/30000 updates, 0.06 s, -44.10 train_loss, -43.51 val_loss\n","4900/30000 updates, 0.06 s, -41.81 train_loss, -41.70 val_loss\n","5000/30000 updates, 0.06 s, -40.53 train_loss, -41.56 val_loss\n","5100/30000 updates, 0.06 s, -41.66 train_loss, -40.52 val_loss\n","5200/30000 updates, 0.06 s, -42.32 train_loss, -42.80 val_loss\n","5300/30000 updates, 0.06 s, -43.24 train_loss, -43.57 val_loss\n","5400/30000 updates, 0.06 s, -42.08 train_loss, -42.05 val_loss\n","5500/30000 updates, 0.06 s, -40.80 train_loss, -44.26 val_loss\n"]},{"name":"stdout","output_type":"stream","text":["5600/30000 updates, 0.06 s, -44.70 train_loss, -44.33 val_loss\n","5700/30000 updates, 0.06 s, -45.57 train_loss, -43.10 val_loss\n","5800/30000 updates, 0.06 s, -43.28 train_loss, -44.60 val_loss\n","5900/30000 updates, 0.06 s, -37.09 train_loss, -37.02 val_loss\n","6000/30000 updates, 0.06 s, -43.71 train_loss, -45.09 val_loss\n","6100/30000 updates, 0.06 s, -40.97 train_loss, -40.32 val_loss\n","6200/30000 updates, 0.06 s, -43.21 train_loss, -43.79 val_loss\n","6300/30000 updates, 0.06 s, -45.39 train_loss, -45.16 val_loss\n","6400/30000 updates, 0.06 s, -45.82 train_loss, -43.42 val_loss\n","6500/30000 updates, 0.06 s, -37.18 train_loss, -40.48 val_loss\n","6600/30000 updates, 0.06 s, -45.31 train_loss, -45.92 val_loss\n","6700/30000 updates, 0.06 s, -46.12 train_loss, -44.83 val_loss\n","6800/30000 updates, 0.06 s, -46.44 train_loss, -45.78 val_loss\n","6900/30000 updates, 0.06 s, -42.21 train_loss, -39.60 val_loss\n","7000/30000 updates, 0.06 s, -45.00 train_loss, -44.52 val_loss\n","7100/30000 updates, 0.06 s, -45.89 train_loss, -45.51 val_loss\n","7200/30000 updates, 0.06 s, -36.07 train_loss, -43.52 val_loss\n","7300/30000 updates, 0.06 s, -45.21 train_loss, -46.47 val_loss\n","7400/30000 updates, 0.06 s, -45.09 train_loss, -44.87 val_loss\n","7500/30000 updates, 0.06 s, -47.03 train_loss, -44.39 val_loss\n","7600/30000 updates, 0.06 s, -41.24 train_loss, -35.74 val_loss\n","7700/30000 updates, 0.06 s, -46.87 train_loss, -46.17 val_loss\n","7800/30000 updates, 0.06 s, -45.65 train_loss, -44.22 val_loss\n","7900/30000 updates, 0.06 s, -46.47 train_loss, -46.40 val_loss\n","8000/30000 updates, 0.06 s, -45.82 train_loss, -45.50 val_loss\n","8100/30000 updates, 0.06 s, -43.31 train_loss, -43.82 val_loss\n","8200/30000 updates, 0.06 s, -40.31 train_loss, -38.98 val_loss\n","8300/30000 updates, 0.06 s, -46.36 train_loss, -45.87 val_loss\n","8400/30000 updates, 0.06 s, -43.31 train_loss, -40.39 val_loss\n","8500/30000 updates, 0.06 s, -42.31 train_loss, -43.77 val_loss\n","8600/30000 updates, 0.06 s, -40.93 train_loss, -41.42 val_loss\n","8700/30000 updates, 0.06 s, -42.56 train_loss, -45.35 val_loss\n","8800/30000 updates, 0.06 s, -45.72 train_loss, -43.88 val_loss\n","8900/30000 updates, 0.06 s, -39.93 train_loss, -35.13 val_loss\n","9000/30000 updates, 0.06 s, -47.39 train_loss, -46.48 val_loss\n","9100/30000 updates, 0.06 s, -45.43 train_loss, -46.04 val_loss\n","9200/30000 updates, 0.06 s, -37.58 train_loss, -33.38 val_loss\n","9300/30000 updates, 0.06 s, -48.23 train_loss, -46.75 val_loss\n","9400/30000 updates, 0.06 s, -46.21 train_loss, -45.63 val_loss\n","9500/30000 updates, 0.06 s, -40.69 train_loss, -44.15 val_loss\n","9600/30000 updates, 0.06 s, -45.96 train_loss, -43.53 val_loss\n","9700/30000 updates, 0.06 s, -46.01 train_loss, -46.20 val_loss\n","9800/30000 updates, 0.06 s, -47.03 train_loss, -45.99 val_loss\n","9900/30000 updates, 0.06 s, -48.02 train_loss, -46.23 val_loss\n","10000/30000 updates, 0.06 s, -44.62 train_loss, -40.98 val_loss\n","10100/30000 updates, 0.06 s, -45.60 train_loss, -47.32 val_loss\n","10200/30000 updates, 0.06 s, -46.33 train_loss, -46.26 val_loss\n","10300/30000 updates, 0.06 s, -43.72 train_loss, -42.72 val_loss\n","10400/30000 updates, 0.06 s, -44.52 train_loss, -43.30 val_loss\n","10500/30000 updates, 0.06 s, -42.87 train_loss, -44.49 val_loss\n","10600/30000 updates, 0.06 s, -44.09 train_loss, -45.66 val_loss\n","10700/30000 updates, 0.06 s, -45.68 train_loss, -46.57 val_loss\n","10800/30000 updates, 0.06 s, -44.09 train_loss, -38.93 val_loss\n","10900/30000 updates, 0.06 s, -46.44 train_loss, -45.35 val_loss\n","11000/30000 updates, 0.06 s, -47.88 train_loss, -46.19 val_loss\n","11100/30000 updates, 0.06 s, -46.62 train_loss, -46.99 val_loss\n","11200/30000 updates, 0.06 s, -47.22 train_loss, -46.42 val_loss\n","11300/30000 updates, 0.06 s, -47.49 train_loss, -47.84 val_loss\n","11400/30000 updates, 0.06 s, -42.88 train_loss, -47.04 val_loss\n","11500/30000 updates, 0.06 s, -48.11 train_loss, -46.66 val_loss\n","11600/30000 updates, 0.06 s, -47.31 train_loss, -46.24 val_loss\n","11700/30000 updates, 0.06 s, -47.85 train_loss, -45.83 val_loss\n","11800/30000 updates, 0.06 s, -45.37 train_loss, -45.39 val_loss\n","11900/30000 updates, 0.06 s, -40.29 train_loss, -41.92 val_loss\n","12000/30000 updates, 0.06 s, -47.87 train_loss, -46.04 val_loss\n","12100/30000 updates, 0.06 s, -47.65 train_loss, -47.29 val_loss\n","12200/30000 updates, 0.06 s, -46.65 train_loss, -46.93 val_loss\n","12300/30000 updates, 0.06 s, -47.44 train_loss, -47.46 val_loss\n","12400/30000 updates, 0.06 s, -48.05 train_loss, -48.01 val_loss\n","12500/30000 updates, 0.06 s, -48.63 train_loss, -47.17 val_loss\n","12600/30000 updates, 0.06 s, -39.96 train_loss, -34.55 val_loss\n","12700/30000 updates, 0.06 s, -47.24 train_loss, -47.57 val_loss\n","12800/30000 updates, 0.06 s, -47.42 train_loss, -47.15 val_loss\n","12900/30000 updates, 0.06 s, -44.35 train_loss, -38.12 val_loss\n","13000/30000 updates, 0.06 s, -48.97 train_loss, -48.22 val_loss\n","13100/30000 updates, 0.06 s, -45.50 train_loss, -43.69 val_loss\n","13200/30000 updates, 0.06 s, -48.65 train_loss, -48.36 val_loss\n","13300/30000 updates, 0.06 s, -46.81 train_loss, -47.96 val_loss\n","13400/30000 updates, 0.06 s, -47.65 train_loss, -47.52 val_loss\n","13500/30000 updates, 0.06 s, -40.11 train_loss, -41.98 val_loss\n","13600/30000 updates, 0.06 s, -46.13 train_loss, -43.79 val_loss\n","13700/30000 updates, 0.06 s, -46.99 train_loss, -47.72 val_loss\n","13800/30000 updates, 0.06 s, -39.31 train_loss, -38.76 val_loss\n","13900/30000 updates, 0.06 s, -48.75 train_loss, -48.25 val_loss\n","14000/30000 updates, 0.06 s, -44.94 train_loss, -47.71 val_loss\n","14100/30000 updates, 0.06 s, -44.41 train_loss, -37.91 val_loss\n","14200/30000 updates, 0.06 s, -45.59 train_loss, -46.67 val_loss\n","14300/30000 updates, 0.06 s, -46.94 train_loss, -47.79 val_loss\n","14400/30000 updates, 0.06 s, -45.01 train_loss, -45.48 val_loss\n","14500/30000 updates, 0.06 s, -45.56 train_loss, -43.47 val_loss\n","14600/30000 updates, 0.06 s, -46.27 train_loss, -46.31 val_loss\n","14700/30000 updates, 0.06 s, -46.74 train_loss, -46.67 val_loss\n","14800/30000 updates, 0.06 s, -47.18 train_loss, -46.19 val_loss\n","14900/30000 updates, 0.06 s, -48.63 train_loss, -46.92 val_loss\n","15000/30000 updates, 0.06 s, -46.73 train_loss, -41.88 val_loss\n","15100/30000 updates, 0.06 s, -39.16 train_loss, -44.50 val_loss\n","15200/30000 updates, 0.06 s, -45.96 train_loss, -48.73 val_loss\n","15300/30000 updates, 0.06 s, -44.56 train_loss, -47.23 val_loss\n","15400/30000 updates, 0.06 s, -48.94 train_loss, -48.59 val_loss\n","15500/30000 updates, 0.07 s, -42.19 train_loss, -40.79 val_loss\n","15600/30000 updates, 0.07 s, -47.42 train_loss, -47.16 val_loss\n","15700/30000 updates, 0.07 s, -47.20 train_loss, -43.97 val_loss\n","15800/30000 updates, 0.06 s, -45.32 train_loss, -46.42 val_loss\n","15900/30000 updates, 0.06 s, -48.04 train_loss, -48.52 val_loss\n","16000/30000 updates, 0.06 s, -45.63 train_loss, -43.37 val_loss\n","16100/30000 updates, 0.06 s, -45.98 train_loss, -44.09 val_loss\n","16200/30000 updates, 0.06 s, -47.33 train_loss, -47.79 val_loss\n","16300/30000 updates, 0.06 s, -46.60 train_loss, -46.12 val_loss\n","16400/30000 updates, 0.06 s, -49.13 train_loss, -48.04 val_loss\n","16500/30000 updates, 0.06 s, -48.02 train_loss, -43.72 val_loss\n","16600/30000 updates, 0.06 s, -45.10 train_loss, -45.96 val_loss\n","16700/30000 updates, 0.06 s, -48.15 train_loss, -47.82 val_loss\n","16800/30000 updates, 0.06 s, -48.08 train_loss, -48.15 val_loss\n","16900/30000 updates, 0.06 s, -47.48 train_loss, -46.48 val_loss\n","17000/30000 updates, 0.06 s, -46.50 train_loss, -47.47 val_loss\n","17100/30000 updates, 0.06 s, -48.64 train_loss, -48.87 val_loss\n","17200/30000 updates, 0.06 s, -44.91 train_loss, -45.82 val_loss\n","17300/30000 updates, 0.06 s, -45.65 train_loss, -47.24 val_loss\n","17400/30000 updates, 0.06 s, -51.02 train_loss, -48.38 val_loss\n","17500/30000 updates, 0.06 s, -45.39 train_loss, -45.88 val_loss\n","17600/30000 updates, 0.06 s, -46.50 train_loss, -48.08 val_loss\n","17700/30000 updates, 0.06 s, -44.26 train_loss, -42.84 val_loss\n","17800/30000 updates, 0.06 s, -48.78 train_loss, -47.72 val_loss\n","17900/30000 updates, 0.06 s, -47.07 train_loss, -47.40 val_loss\n","18000/30000 updates, 0.06 s, -45.44 train_loss, -46.06 val_loss\n","18100/30000 updates, 0.06 s, -47.24 train_loss, -46.62 val_loss\n","18200/30000 updates, 0.06 s, -49.44 train_loss, -49.49 val_loss\n","18300/30000 updates, 0.06 s, -46.59 train_loss, -36.68 val_loss\n","18400/30000 updates, 0.06 s, -49.18 train_loss, -48.56 val_loss\n","18500/30000 updates, 0.06 s, -50.77 train_loss, -49.10 val_loss\n","18600/30000 updates, 0.06 s, -48.54 train_loss, -45.80 val_loss\n","18700/30000 updates, 0.06 s, -47.88 train_loss, -48.17 val_loss\n","18800/30000 updates, 0.06 s, -47.77 train_loss, -45.03 val_loss\n","18900/30000 updates, 0.06 s, -48.60 train_loss, -49.15 val_loss\n","19000/30000 updates, 0.06 s, -50.93 train_loss, -48.99 val_loss\n","19100/30000 updates, 0.06 s, -48.04 train_loss, -45.44 val_loss\n","19200/30000 updates, 0.06 s, -46.09 train_loss, -48.38 val_loss\n","19300/30000 updates, 0.06 s, -46.39 train_loss, -45.64 val_loss\n","19400/30000 updates, 0.06 s, -48.01 train_loss, -46.91 val_loss\n","19500/30000 updates, 0.07 s, -47.84 train_loss, -47.99 val_loss\n","19600/30000 updates, 0.07 s, -47.31 train_loss, -47.47 val_loss\n","19700/30000 updates, 0.06 s, -47.81 train_loss, -46.59 val_loss\n","19800/30000 updates, 0.06 s, -45.61 train_loss, -45.15 val_loss\n","19900/30000 updates, 0.06 s, -37.08 train_loss, -37.23 val_loss\n","20000/30000 updates, 0.06 s, -43.78 train_loss, -45.64 val_loss\n","20100/30000 updates, 0.06 s, -46.11 train_loss, -46.85 val_loss\n","20200/30000 updates, 0.06 s, -48.81 train_loss, -49.86 val_loss\n","20300/30000 updates, 0.06 s, -47.53 train_loss, -45.00 val_loss\n","20400/30000 updates, 0.06 s, -47.79 train_loss, -48.38 val_loss\n","20500/30000 updates, 0.06 s, -48.17 train_loss, -46.48 val_loss\n","20600/30000 updates, 0.06 s, -33.13 train_loss, -43.36 val_loss\n","20700/30000 updates, 0.07 s, -46.31 train_loss, -47.34 val_loss\n","20800/30000 updates, 0.07 s, -44.21 train_loss, -46.40 val_loss\n","20900/30000 updates, 0.06 s, -42.45 train_loss, -45.08 val_loss\n","21000/30000 updates, 0.06 s, -50.61 train_loss, -48.14 val_loss\n","21100/30000 updates, 0.06 s, -47.43 train_loss, -45.34 val_loss\n","21200/30000 updates, 0.06 s, -48.23 train_loss, -48.11 val_loss\n","21300/30000 updates, 0.06 s, -47.06 train_loss, -49.64 val_loss\n","21400/30000 updates, 0.06 s, -44.58 train_loss, -45.10 val_loss\n","21500/30000 updates, 0.06 s, -47.85 train_loss, -46.67 val_loss\n","21600/30000 updates, 0.06 s, -50.05 train_loss, -49.75 val_loss\n","21700/30000 updates, 0.06 s, -47.95 train_loss, -47.14 val_loss\n","21800/30000 updates, 0.06 s, -47.88 train_loss, -48.16 val_loss\n","21900/30000 updates, 0.07 s, -38.11 train_loss, -42.42 val_loss\n","22000/30000 updates, 0.07 s, -49.94 train_loss, -49.68 val_loss\n","22100/30000 updates, 0.07 s, -35.22 train_loss, -41.24 val_loss\n","22200/30000 updates, 0.06 s, -48.75 train_loss, -49.86 val_loss\n","22300/30000 updates, 0.06 s, -36.97 train_loss, -42.94 val_loss\n","22400/30000 updates, 0.06 s, -46.94 train_loss, -47.60 val_loss\n","22500/30000 updates, 0.06 s, -48.60 train_loss, -48.30 val_loss\n","22600/30000 updates, 0.06 s, -48.04 train_loss, -47.59 val_loss\n","22700/30000 updates, 0.06 s, -42.30 train_loss, -42.11 val_loss\n","22800/30000 updates, 0.06 s, -48.76 train_loss, -46.56 val_loss\n","22900/30000 updates, 0.06 s, -48.37 train_loss, -48.11 val_loss\n","23000/30000 updates, 0.06 s, -47.81 train_loss, -48.91 val_loss\n","23100/30000 updates, 0.06 s, -47.59 train_loss, -44.61 val_loss\n","23200/30000 updates, 0.06 s, -48.51 train_loss, -48.70 val_loss\n","23300/30000 updates, 0.06 s, -50.92 train_loss, -50.61 val_loss\n","23400/30000 updates, 0.06 s, -46.46 train_loss, -48.51 val_loss\n","23500/30000 updates, 0.06 s, -48.97 train_loss, -47.88 val_loss\n","23600/30000 updates, 0.06 s, -48.04 train_loss, -45.68 val_loss\n","23700/30000 updates, 0.06 s, -37.08 train_loss, -38.83 val_loss\n","23800/30000 updates, 0.06 s, -47.78 train_loss, -48.35 val_loss\n","23900/30000 updates, 0.06 s, -37.45 train_loss, -43.32 val_loss\n","24000/30000 updates, 0.06 s, -49.20 train_loss, -48.31 val_loss\n","24100/30000 updates, 0.06 s, -47.83 train_loss, -45.54 val_loss\n","24200/30000 updates, 0.06 s, -46.96 train_loss, -46.15 val_loss\n","24300/30000 updates, 0.06 s, -50.14 train_loss, -49.94 val_loss\n","24400/30000 updates, 0.06 s, -50.64 train_loss, -49.82 val_loss\n","24500/30000 updates, 0.06 s, -45.48 train_loss, -45.19 val_loss\n","24600/30000 updates, 0.06 s, -49.29 train_loss, -49.81 val_loss\n","24700/30000 updates, 0.06 s, -41.85 train_loss, -35.67 val_loss\n","24800/30000 updates, 0.06 s, -49.09 train_loss, -49.38 val_loss\n","24900/30000 updates, 0.06 s, -48.45 train_loss, -46.83 val_loss\n","25000/30000 updates, 0.06 s, -47.69 train_loss, -47.01 val_loss\n","25100/30000 updates, 0.06 s, -48.73 train_loss, -44.68 val_loss\n","25200/30000 updates, 0.06 s, -42.52 train_loss, -44.04 val_loss\n","25300/30000 updates, 0.06 s, -48.30 train_loss, -46.92 val_loss\n","25400/30000 updates, 0.06 s, -7.37 train_loss, -39.15 val_loss\n","25500/30000 updates, 0.06 s, -48.82 train_loss, -48.85 val_loss\n","25600/30000 updates, 0.06 s, -48.91 train_loss, -48.72 val_loss\n","25700/30000 updates, 0.06 s, -43.34 train_loss, -48.38 val_loss\n","25800/30000 updates, 0.06 s, -49.60 train_loss, -47.12 val_loss\n","25900/30000 updates, 0.06 s, -48.90 train_loss, -46.05 val_loss\n","26000/30000 updates, 0.06 s, -48.38 train_loss, -48.61 val_loss\n","26100/30000 updates, 0.06 s, -48.75 train_loss, -49.65 val_loss\n","26200/30000 updates, 0.06 s, -41.50 train_loss, -41.58 val_loss\n","26300/30000 updates, 0.06 s, -46.45 train_loss, -49.11 val_loss\n","26400/30000 updates, 0.06 s, -49.38 train_loss, -49.80 val_loss\n","26500/30000 updates, 0.06 s, -45.76 train_loss, -45.20 val_loss\n","26600/30000 updates, 0.07 s, -51.20 train_loss, -49.47 val_loss\n","26700/30000 updates, 0.06 s, -46.09 train_loss, -48.45 val_loss\n","26800/30000 updates, 0.06 s, -45.12 train_loss, -44.84 val_loss\n","26900/30000 updates, 0.06 s, -50.14 train_loss, -49.79 val_loss\n","27000/30000 updates, 0.06 s, -48.83 train_loss, -45.18 val_loss\n","27100/30000 updates, 0.06 s, -49.71 train_loss, -48.66 val_loss\n","27200/30000 updates, 0.06 s, -49.03 train_loss, -49.78 val_loss\n","27300/30000 updates, 0.06 s, -43.28 train_loss, -46.28 val_loss\n","27400/30000 updates, 0.06 s, -49.03 train_loss, -49.74 val_loss\n","27500/30000 updates, 0.06 s, -43.07 train_loss, -42.56 val_loss\n","27600/30000 updates, 0.06 s, -49.54 train_loss, -46.18 val_loss\n","27700/30000 updates, 0.06 s, -45.22 train_loss, -43.42 val_loss\n","27800/30000 updates, 0.06 s, -35.19 train_loss, -42.67 val_loss\n","27900/30000 updates, 0.06 s, -46.64 train_loss, -48.96 val_loss\n","28000/30000 updates, 0.06 s, -48.60 train_loss, -47.49 val_loss\n","28100/30000 updates, 0.06 s, -47.54 train_loss, -50.39 val_loss\n","28200/30000 updates, 0.06 s, -46.78 train_loss, -39.04 val_loss\n","28300/30000 updates, 0.06 s, -51.69 train_loss, -49.96 val_loss\n","28400/30000 updates, 0.06 s, -51.42 train_loss, -48.76 val_loss\n","28500/30000 updates, 0.06 s, -45.95 train_loss, -45.25 val_loss\n","28600/30000 updates, 0.06 s, -45.32 train_loss, -49.66 val_loss\n","28700/30000 updates, 0.06 s, -48.74 train_loss, -49.88 val_loss\n","28800/30000 updates, 0.06 s, -42.36 train_loss, -43.29 val_loss\n","28900/30000 updates, 0.06 s, -46.19 train_loss, -49.57 val_loss\n","29000/30000 updates, 0.06 s, -47.51 train_loss, -48.93 val_loss\n","29100/30000 updates, 0.06 s, -46.18 train_loss, -48.60 val_loss\n","29200/30000 updates, 0.06 s, -49.08 train_loss, -44.30 val_loss\n","29300/30000 updates, 0.06 s, -47.67 train_loss, -48.26 val_loss\n","29400/30000 updates, 0.06 s, -48.24 train_loss, -49.00 val_loss\n","29500/30000 updates, 0.06 s, -45.51 train_loss, -46.16 val_loss\n","29600/30000 updates, 0.06 s, -48.05 train_loss, -50.28 val_loss\n","29700/30000 updates, 0.06 s, -48.16 train_loss, -46.48 val_loss\n","29800/30000 updates, 0.06 s, -44.32 train_loss, -43.24 val_loss\n","29900/30000 updates, 0.06 s, -50.58 train_loss, -49.69 val_loss\n"]}],"source":["batch_pointer = 0\n","\n","start = time.time()\n","best = float(\"inf\")\n","\n","\n","for i in range(max_iter):\n","    x_batch = Xz[batch_pointer: batch_pointer + batch_size, :]\n","    s_batch = S[batch_pointer: batch_pointer + batch_size, :]\n","\n","    _, _loss, _step = sess.run([train_op, loss, global_step], {x_pl: x_batch, s_pl: s_batch, n_pl: n_samples})\n","\n","    batch_pointer += batch_size\n","\n","    if batch_pointer > N - batch_size:\n","        batch_pointer = 0\n","\n","        p = np.random.permutation(N)\n","        Xz = Xz[p, :]\n","        S = S[p, :]\n","\n","    if i % 100 == 0:\n","        took = time.time() - start\n","        start = time.time()\n","\n","        # --- change the following batch if you want a true validation set\n","        x_batch = __Xz\n","        s_batch = __S\n","        xorg_batch = __X\n","        val_loss, _step = sess.run([loss, global_step], {x_pl: x_batch, s_pl: s_batch, n_pl: n_samples})\n","        # rmse = imputationRMSE(sess, xorg_batch, Xnan, 10_000)[0]\n","\n","        print(\"{0}/{1} updates, {2:.2f} s, {3:.2f} train_loss, {4:.2f} val_loss\".format(i, max_iter, took, _loss, val_loss))\n","        # print(f'RMSE:{rmse}')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Single imputation RMSE\n","The *self-normalized importance sampling* approach for the MIWAE is described in this [paper](https://arxiv.org/pdf/1812.02633.pdf). This needs to be modified slightly in the MNAR case to account for the missing model, as described in the not-MIWAE paper"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":["def imputationRMSE(sess, Xorg, Xnan, L):\n","\n","    N = len(Xorg)\n","\n","    Xz = Xnan.copy()\n","    Xz[np.isnan(Xnan)] = 0\n","    S = np.array(~np.isnan(Xnan), dtype=np.float32)\n","\n","    def softmax(x):\n","        e_x = np.exp(x - np.max(x, axis=1)[:, None])\n","        return e_x / e_x.sum(axis=1)[:, None]\n","\n","    def imp(xz, s, L):\n","        _mu, _log_p_x_given_z, _log_p_z, _log_q_z_given_x = sess.run(\n","            [mu, log_p_x_given_z, log_p_z, log_q_z_given_x],\n","            {x_pl: xz, s_pl: s, n_pl: L})\n","\n","        wl = softmax(_log_p_x_given_z + _log_p_z - _log_q_z_given_x)\n","\n","        xm = np.sum((_mu.T * wl.T).T, axis=1)\n","        xmix = xz + xm * (1 - s)\n","\n","        return _mu, wl, xm, xmix\n","\n","    XM = np.zeros_like(Xorg)\n","\n","    for i in range(N):\n","\n","        xz = Xz[i, :][None, :]\n","        s = S[i, :][None, :]\n","\n","        _mu, wl, xm, xmix = imp(xz, s, L)\n","\n","        XM[i, :] = xm\n","\n","        # if i % 100 == 0:\n","        #     print('{0} / {1}'.format(i, N))\n","\n","    return np.sqrt(np.sum((Xorg - XM) ** 2 * (1 - S)) / np.sum(1 - S)), XM\n","\n","\n","def not_imputationRMSE(sess, Xorg, Xnan, L):\n","\n","    N = len(Xorg)\n","\n","    Xz = Xnan.copy()\n","    Xz[np.isnan(Xnan)] = 0\n","    S = np.array(~np.isnan(Xnan), dtype=np.float32)\n","\n","    def softmax(x):\n","        e_x = np.exp(x - np.max(x, axis=1)[:, None])\n","        return e_x / e_x.sum(axis=1)[:, None]\n","\n","    def imp(xz, s, L):\n","        _mu, _log_p_x_given_z, _log_p_z, _log_q_z_given_x, _log_p_s_given_x  = sess.run(\n","            [mu, log_p_x_given_z, log_p_z, log_q_z_given_x, log_p_s_given_x],\n","            {x_pl: xz, s_pl: s, n_pl: L})\n","\n","        wl = softmax(_log_p_x_given_z + _log_p_s_given_x + _log_p_z - _log_q_z_given_x)\n","\n","        xm = np.sum((_mu.T * wl.T).T, axis=1)\n","        xmix = xz + xm * (1 - s)\n","\n","        return _mu, wl, xm, xmix\n","\n","    XM = np.zeros_like(Xorg)\n","\n","    for i in range(N):\n","\n","        xz = Xz[i, :][None, :]\n","        s = S[i, :][None, :]\n","\n","        _mu, wl, xm, xmix = imp(xz, s, L)\n","\n","        XM[i, :] = xm\n","\n","        if i % 100 == 0:\n","            print('{0} / {1}'.format(i, N))\n","\n","    return np.sqrt(np.sum((Xorg - XM) ** 2 * (1 - S)) / np.sum(1 - S)), XM\n"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate the single imputation RMSE using 10k importance samples\n","If you used the MIWAE loss use the imputationRMSE \n","\n","If you used the notMIWAE loss use the not_imputationRMSE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 / 4898\n","100 / 4898\n","200 / 4898\n","300 / 4898\n","400 / 4898\n","500 / 4898\n","600 / 4898\n","700 / 4898\n","800 / 4898\n","900 / 4898\n","1000 / 4898\n","1100 / 4898\n","1200 / 4898\n","1300 / 4898\n","1400 / 4898\n","1500 / 4898\n","1600 / 4898\n","1700 / 4898\n","1800 / 4898\n","1900 / 4898\n","2000 / 4898\n","2100 / 4898\n","2200 / 4898\n","2300 / 4898\n","2400 / 4898\n","2500 / 4898\n","2600 / 4898\n","2700 / 4898\n","2800 / 4898\n","2900 / 4898\n","3000 / 4898\n","3100 / 4898\n","3200 / 4898\n","3300 / 4898\n","3400 / 4898\n","3500 / 4898\n","3600 / 4898\n","3700 / 4898\n","3800 / 4898\n","3900 / 4898\n","4000 / 4898\n","4100 / 4898\n","4200 / 4898\n","4300 / 4898\n","4400 / 4898\n","4500 / 4898\n","4600 / 4898\n","4700 / 4898\n","4800 / 4898\n","imputation RMSE:  1.1117022737688882\n"]}],"source":["# ---- S has been permuted during training, so just reinstantiate it\n","S = np.array(~np.isnan(Xnan), dtype=np.float32)\n","\n","rmse, imputations = not_imputationRMSE(sess, Xtrain, Xnan, 10000)\n","# rmse, imputations = imputationRMSE(sess, Xtrain, Xnan, 10000)\n","\n","print(\"imputation RMSE: \", rmse)"]},{"cell_type":"markdown","metadata":{},"source":["### Compare to missForest and MICE"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":["from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[1434], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m estimator \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      2\u001b[0m imp \u001b[38;5;241m=\u001b[39m IterativeImputer(estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mimp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXnan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m Xrec \u001b[38;5;241m=\u001b[39m imp\u001b[38;5;241m.\u001b[39mtransform(Xnan)\n\u001b[0;32m      5\u001b[0m rmse_mf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum((Xtrain \u001b[38;5;241m-\u001b[39m Xrec) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m S)) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m S))\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:879\u001b[0m, in \u001b[0;36mIterativeImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    863\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X` and return self.\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 879\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:765\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[0;32m    762\u001b[0m     neighbor_feat_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[0;32m    763\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[0;32m    764\u001b[0m     )\n\u001b[1;32m--> 765\u001b[0m     Xt, estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impute_one_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_missing_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneighbor_feat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m     estimator_triplet \u001b[38;5;241m=\u001b[39m _ImputerTriplet(\n\u001b[0;32m    774\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[0;32m    775\u001b[0m     )\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_\u001b[38;5;241m.\u001b[39mappend(estimator_triplet)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:412\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[1;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[0;32m    402\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    403\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    405\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    406\u001b[0m     )\n\u001b[0;32m    407\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[0;32m    408\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[0;32m    410\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    411\u001b[0m     )\n\u001b[1;32m--> 412\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# if no missing values, don't predict\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(missing_row_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n","File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["estimator = RandomForestRegressor(n_estimators=100)\n","imp = IterativeImputer(estimator=estimator)\n","imp.fit(Xnan)\n","Xrec = imp.transform(Xnan)\n","rmse_mf = np.sqrt(np.sum((Xtrain - Xrec) ** 2 * (1 - S)) / np.sum(1 - S))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["missForst imputation RMSE:  1.6343816564019316\n"]}],"source":["print(\"missForst imputation RMSE: \", rmse_mf)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":["imp = IterativeImputer(max_iter=100)\n","imp.fit(Xnan)\n","Xrec = imp.transform(Xnan)\n","RMSE_iter = np.sqrt(np.sum((Xtrain - Xrec) ** 2 * (1 - S)) / np.sum(1 - S))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MICE, imputation RMSE 1.4102763723316922\n"]}],"source":["print(\"MICE, imputation RMSE\", RMSE_iter)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["[<tf.Variable 'data_process/logstd:0' shape=() dtype=float32>,\n"," <tf.Variable 'l_enc1/kernel:0' shape=(11, 128) dtype=float32>,\n"," <tf.Variable 'l_enc1/bias:0' shape=(128,) dtype=float32>,\n"," <tf.Variable 'l_enc2/kernel:0' shape=(128, 128) dtype=float32>,\n"," <tf.Variable 'l_enc2/bias:0' shape=(128,) dtype=float32>,\n"," <tf.Variable 'q_mu/kernel:0' shape=(128, 10) dtype=float32>,\n"," <tf.Variable 'q_mu/bias:0' shape=(10,) dtype=float32>,\n"," <tf.Variable 'q_logstd/kernel:0' shape=(128, 10) dtype=float32>,\n"," <tf.Variable 'q_logstd/bias:0' shape=(10,) dtype=float32>,\n"," <tf.Variable 'mu/kernel:0' shape=(10, 11) dtype=float32>,\n"," <tf.Variable 'mu/bias:0' shape=(11,) dtype=float32>,\n"," <tf.Variable 'W:0' shape=(1, 1, 11) dtype=float32>,\n"," <tf.Variable 'b:0' shape=(1, 1, 11) dtype=float32>]"]},"execution_count":1256,"metadata":{},"output_type":"execute_result"}],"source":["trainable_variables"]},{"cell_type":"markdown","metadata":{},"source":["### Inspect the learned missing model\n","There is a separate missing process in each feature dimesion, inspect each of them, plot as function of feature value."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["_W, _b = sess.run([W, b])\n","x = np.linspace(-2, 2, 100)\n","\n","def sigmoid(logits):\n","    return 1 / (1 + np.exp(-logits))\n","\n","\n","plt.figure()\n","\n","for d in range(D // 2):\n","    logits = _W[0][0][d] * (x - _b[0][0][d])\n","    psx = sigmoid(logits)\n","    plt.plot(x, psx)\n","\n","plt.xlabel('feature value')\n","plt.ylabel('$p(s|x)$')\n","plt.show()\n","plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["(array([[[-15.064675 ,  -6.5605564, -13.927918 , -11.371145 ,\n","           -9.007028 ,   4.712978 ,  -2.2390034,  -1.4327152,\n","           -5.2509413,   4.3905253,   4.8927236]]], dtype=float32),\n"," array([[[-0.05938366, -0.2097743 , -0.06150096, -0.13324064,\n","          -0.15291208, -5.173197  ,  6.1473246 ,  6.939733  ,\n","           6.0418167 , -5.5806217 , -5.021612  ]]], dtype=float32))"]},"execution_count":1258,"metadata":{},"output_type":"execute_result"}],"source":["_W, _b"]},{"cell_type":"markdown","metadata":{},"source":["This should illustrate that the probability of the feature value being observed when it is below the feature mean should be close to 1, while the probability of being observed above the feature mean should be close to 0."]},{"cell_type":"markdown","metadata":{},"source":["### Close the session"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true},"outputs":[],"source":["# sess.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":2}
